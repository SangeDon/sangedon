{"meta":{"title":"Sange","subtitle":"心即理","description":null,"author":"董先生","url":"https://sangedon.cn","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2020-09-23T05:14:55.456Z","updated":"2020-09-23T05:14:55.456Z","comments":false,"path":"/404.html","permalink":"https://sangedon.cn//404.html","excerpt":"","text":""},{"title":"关于","date":"2019-05-16T08:32:24.000Z","updated":"2020-10-22T14:11:35.805Z","comments":false,"path":"about/index.html","permalink":"https://sangedon.cn/about/index.html","excerpt":"","text":"Email: sange.dong@outlook.com Wechat: ssangedon"},{"title":"archives","date":"2019-05-16T08:30:04.000Z","updated":"2020-09-23T05:14:55.474Z","comments":true,"path":"archives/index.html","permalink":"https://sangedon.cn/archives/index.html","excerpt":"","text":""},{"title":"分类","date":"2019-05-16T08:32:41.000Z","updated":"2020-09-23T05:14:55.476Z","comments":true,"path":"categories/index.html","permalink":"https://sangedon.cn/categories/index.html","excerpt":"","text":""},{"title":"书单","date":"2020-09-23T05:14:55.475Z","updated":"2020-09-23T05:14:55.475Z","comments":false,"path":"books/index.html","permalink":"https://sangedon.cn/books/index.html","excerpt":"","text":""},{"title":"留言本","date":"2019-05-16T08:32:41.000Z","updated":"2020-10-16T05:00:06.367Z","comments":true,"path":"guestbook/index.html","permalink":"https://sangedon.cn/guestbook/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2020-09-23T05:14:55.478Z","updated":"2020-09-23T05:14:55.478Z","comments":true,"path":"repository/index.html","permalink":"https://sangedon.cn/repository/index.html","excerpt":"","text":""},{"title":"日志","date":"2020-09-23T05:14:55.477Z","updated":"2020-09-23T05:14:55.477Z","comments":true,"path":"record/index.html","permalink":"https://sangedon.cn/record/index.html","excerpt":"","text":"水光潋滟晴方好，山色空蒙雨亦奇"},{"title":"友情链接","date":"2020-09-23T05:14:55.477Z","updated":"2020-09-23T05:14:55.477Z","comments":true,"path":"links/index.html","permalink":"https://sangedon.cn/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-05-16T08:28:32.000Z","updated":"2020-09-23T05:14:55.479Z","comments":true,"path":"tags/index.html","permalink":"https://sangedon.cn/tags/index.html","excerpt":"","text":""},{"title":"schedule","date":"2019-05-16T08:30:28.000Z","updated":"2020-09-23T05:14:55.479Z","comments":true,"path":"schedule/index.html","permalink":"https://sangedon.cn/schedule/index.html","excerpt":"","text":""}],"posts":[{"title":"docker-compose.yml 写法解析","slug":"docker-compose-yml-写法解析","date":"2020-11-15T13:25:20.000Z","updated":"2020-11-16T11:44:50.450Z","comments":true,"path":"paper/docker-compose-yml-写法解析/","link":"","permalink":"https://sangedon.cn/paper/docker-compose-yml-写法解析/","excerpt":"","text":"Compose 是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，通过使用 YML 文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。 下面是docker-compose.yml 配置文件常用字段解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242version # 指定 compose 文件的版本services # 定义所有的 service 信息, services 下面的第一级别的 key 既是一个 service 的名称build # 指定包含构建上下文的路径, 或作为一个对象，该对象具有 context 和指定的 dockerfile 文件以及 args 参数值 context # context: 指定 Dockerfile 文件所在的路径 dockerfile # dockerfile: 指定 context 指定的目录下面的 Dockerfile 的名称(默认为 Dockerfile) args # args: Dockerfile 在 build 过程中需要的参数 (等同于 docker container build --build-arg 的作用) cache_from # v3.2中新增的参数, 指定缓存的镜像列表 (等同于 docker container build --cache_from 的作用) labels # v3.3中新增的参数, 设置镜像的元数据 (等同于 docker container build --labels 的作用) shm_size # v3.5中新增的参数, 设置容器 /dev/shm 分区的大小 (等同于 docker container build --shm-size 的作用)command # 覆盖容器启动后默认执行的命令, 支持 shell 格式和 [] 格式configs # 不知道怎么用cgroup_parent # 不知道怎么用container_name # 指定容器的名称 (等同于 docker run --name 的作用)credential_spec # 不知道怎么用deploy # v3 版本以上, 指定与部署和运行服务相关的配置, deploy 部分是 docker stack 使用的, docker stack 依赖 docker swarm endpoint_mode # v3.3 版本中新增的功能, 指定服务暴露的方式 vip # Docker 为该服务分配了一个虚拟 IP(VIP), 作为客户端的访问服务的地址 dnsrr # DNS轮询, Docker 为该服务设置 DNS 条目, 使得服务名称的 DNS 查询返回一个 IP 地址列表, 客户端直接访问其中的一个地址 labels # 指定服务的标签，这些标签仅在服务上设置 mode # 指定 deploy 的模式 global # 每个集群节点都只有一个容器 replicated # 用户可以指定集群中容器的数量(默认) placement # 不知道怎么用 replicas # deploy 的 mode 为 replicated 时, 指定容器副本的数量 resources # 资源限制 limits # 设置容器的资源限制 cpus: \"0.5\" # 设置该容器最多只能使用 50% 的 CPU memory: 50M # 设置该容器最多只能使用 50M 的内存空间 reservations # 设置为容器预留的系统资源(随时可用) cpus: \"0.2\" # 为该容器保留 20% 的 CPU memory: 20M # 为该容器保留 20M 的内存空间 restart_policy # 定义容器重启策略, 用于代替 restart 参数 condition # 定义容器重启策略(接受三个参数) none # 不尝试重启 on-failure # 只有当容器内部应用程序出现问题才会重启 any # 无论如何都会尝试重启(默认) delay # 尝试重启的间隔时间(默认为 0s) max_attempts # 尝试重启次数(默认一直尝试重启) window # 检查重启是否成功之前的等待时间(即如果容器启动了, 隔多少秒之后去检测容器是否正常, 默认 0s) update_config # 用于配置滚动更新配置 parallelism # 一次性更新的容器数量 delay # 更新一组容器之间的间隔时间 failure_action # 定义更新失败的策略 continue # 继续更新 rollback # 回滚更新 pause # 暂停更新(默认) monitor # 每次更新后的持续时间以监视更新是否失败(单位: ns|us|ms|s|m|h) (默认为0) max_failure_ratio # 回滚期间容忍的失败率(默认值为0) order # v3.4 版本中新增的参数, 回滚期间的操作顺序 stop-first #旧任务在启动新任务之前停止(默认) start-first #首先启动新任务, 并且正在运行的任务暂时重叠 rollback_config # v3.7 版本中新增的参数, 用于定义在 update_config 更新失败的回滚策略 parallelism # 一次回滚的容器数, 如果设置为0, 则所有容器同时回滚 delay # 每个组回滚之间的时间间隔(默认为0) failure_action # 定义回滚失败的策略 continue # 继续回滚 pause # 暂停回滚 monitor # 每次回滚任务后的持续时间以监视失败(单位: ns|us|ms|s|m|h) (默认为0) max_failure_ratio # 回滚期间容忍的失败率(默认值0) order # 回滚期间的操作顺序 stop-first # 旧任务在启动新任务之前停止(默认) start-first # 首先启动新任务, 并且正在运行的任务暂时重叠 注意： 支持 docker-compose up 和 docker-compose run 但不支持 docker stack deploy 的子选项 security_opt container_name devices tmpfs stop_signal links cgroup_parent network_mode external_links restart build userns_mode sysctlsdevices # 指定设备映射列表 (等同于 docker run --device 的作用)depends_on # 定义容器启动顺序 (此选项解决了容器之间的依赖关系， 此选项在 v3 版本中 使用 swarm 部署时将忽略该选项) 示例： docker-compose up 以依赖顺序启动服务，下面例子中 redis 和 db 服务在 web 启动前启动 默认情况下使用 docker-compose up web 这样的方式启动 web 服务时，也会启动 redis 和 db 两个服务，因为在配置文件中定义了依赖关系 version: '3' services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres dns # 设置 DNS 地址(等同于 docker run --dns 的作用)dns_search # 设置 DNS 搜索域(等同于 docker run --dns-search 的作用)tmpfs # v2 版本以上, 挂载目录到容器中, 作为容器的临时文件系统(等同于 docker run --tmpfs 的作用, 在使用 swarm 部署时将忽略该选项)entrypoint # 覆盖容器的默认 entrypoint 指令 (等同于 docker run --entrypoint 的作用)env_file # 从指定文件中读取变量设置为容器中的环境变量, 可以是单个值或者一个文件列表, 如果多个文件中的变量重名则后面的变量覆盖前面的变量, environment 的值覆盖 env_file 的值 文件格式： RACK_ENV=development environment # 设置环境变量， environment 的值可以覆盖 env_file 的值 (等同于 docker run --env 的作用)expose # 暴露端口, 但是不能和宿主机建立映射关系, 类似于 Dockerfile 的 EXPOSE 指令external_links # 连接不在 docker-compose.yml 中定义的容器或者不在 compose 管理的容器(docker run 启动的容器, 在 v3 版本中使用 swarm 部署时将忽略该选项)extra_hosts # 添加 host 记录到容器中的 /etc/hosts 中 (等同于 docker run --add-host 的作用)healthcheck # v2.1 以上版本, 定义容器健康状态检查, 类似于 Dockerfile 的 HEALTHCHECK 指令 test # 检查容器检查状态的命令, 该选项必须是一个字符串或者列表, 第一项必须是 NONE, CMD 或 CMD-SHELL, 如果其是一个字符串则相当于 CMD-SHELL 加该字符串 NONE # 禁用容器的健康状态检测 CMD # test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"] CMD-SHELL # test: [\"CMD-SHELL\", \"curl -f http://localhost || exit 1\"] 或者 test: curl -f https://localhost || exit 1 interval: 1m30s # 每次检查之间的间隔时间 timeout: 10s # 运行命令的超时时间 retries: 3 # 重试次数 start_period: 40s # v3.4 以上新增的选项, 定义容器启动时间间隔 disable: true # true 或 false, 表示是否禁用健康状态检测和 test: NONE 相同image # 指定 docker 镜像, 可以是远程仓库镜像、本地镜像init # v3.7 中新增的参数, true 或 false 表示是否在容器中运行一个 init, 它接收信号并传递给进程isolation # 隔离容器技术, 在 Linux 中仅支持 default 值labels # 使用 Docker 标签将元数据添加到容器, 与 Dockerfile 中的 LABELS 类似links # 链接到其它服务中的容器, 该选项是 docker 历史遗留的选项, 目前已被用户自定义网络名称空间取代, 最终有可能被废弃 (在使用 swarm 部署时将忽略该选项)logging # 设置容器日志服务 driver # 指定日志记录驱动程序, 默认 json-file (等同于 docker run --log-driver 的作用) options # 指定日志的相关参数 (等同于 docker run --log-opt 的作用) max-size # 设置单个日志文件的大小, 当到达这个值后会进行日志滚动操作 max-file # 日志文件保留的数量network_mode # 指定网络模式 (等同于 docker run --net 的作用, 在使用 swarm 部署时将忽略该选项) networks # 将容器加入指定网络 (等同于 docker network connect 的作用), networks 可以位于 compose 文件顶级键和 services 键的二级键 aliases # 同一网络上的容器可以使用服务名称或别名连接到其中一个服务的容器 ipv4_address # IP V4 格式 ipv6_address # IP V6 格式 示例: version: '3.7' services: test: image: nginx:1.14-alpine container_name: mynginx command: ifconfig networks: app_net: # 调用下面 networks 定义的 app_net 网络 ipv4_address: 172.16.238.10 networks: app_net: driver: bridge ipam: driver: default config: - subnet: 172.16.238.0/24pid: 'host' # 共享宿主机的 进程空间(PID)ports # 建立宿主机和容器之间的端口映射关系, ports 支持两种语法格式 SHORT 语法格式示例: - \"3000\" # 暴露容器的 3000 端口, 宿主机的端口由 docker 随机映射一个没有被占用的端口 - \"3000-3005\" # 暴露容器的 3000 到 3005 端口, 宿主机的端口由 docker 随机映射没有被占用的端口 - \"8000:8000\" # 容器的 8000 端口和宿主机的 8000 端口建立映射关系 - \"9090-9091:8080-8081\" - \"127.0.0.1:8001:8001\" # 指定映射宿主机的指定地址的 - \"127.0.0.1:5000-5010:5000-5010\" - \"6060:6060/udp\" # 指定协议 LONG 语法格式示例:(v3.2 新增的语法格式) ports: - target: 80 # 容器端口 published: 8080 # 宿主机端口 protocol: tcp # 协议类型 mode: host # host 在每个节点上发布主机端口, ingress 对于群模式端口进行负载均衡secrets # 不知道怎么用security_opt # 为每个容器覆盖默认的标签 (在使用 swarm 部署时将忽略该选项)stop_grace_period # 指定在发送了 SIGTERM 信号之后, 容器等待多少秒之后退出(默认 10s)stop_signal # 指定停止容器发送的信号 (默认为 SIGTERM 相当于 kill PID; SIGKILL 相当于 kill -9 PID; 在使用 swarm 部署时将忽略该选项)sysctls # 设置容器中的内核参数 (在使用 swarm 部署时将忽略该选项)ulimits # 设置容器的 limituserns_mode # 如果Docker守护程序配置了用户名称空间, 则禁用此服务的用户名称空间 (在使用 swarm 部署时将忽略该选项)volumes # 定义容器和宿主机的卷映射关系, 其和 networks 一样可以位于 services 键的二级键和 compose 顶级键, 如果需要跨服务间使用则在顶级键定义, 在 services 中引用 SHORT 语法格式示例: volumes: - /var/lib/mysql # 映射容器内的 /var/lib/mysql 到宿主机的一个随机目录中 - /opt/data:/var/lib/mysql # 映射容器内的 /var/lib/mysql 到宿主机的 /opt/data - ./cache:/tmp/cache # 映射容器内的 /var/lib/mysql 到宿主机 compose 文件所在的位置 - ~/configs:/etc/configs/:ro # 映射容器宿主机的目录到容器中去, 权限只读 - datavolume:/var/lib/mysql # datavolume 为 volumes 顶级键定义的目录, 在此处直接调用 LONG 语法格式示例:(v3.2 新增的语法格式) version: \"3.2\" services: web: image: nginx:alpine ports: - \"80:80\" volumes: - type: volume # mount 的类型, 必须是 bind、volume 或 tmpfs source: mydata # 宿主机目录 target: /data # 容器目录 volume: # 配置额外的选项, 其 key 必须和 type 的值相同 nocopy: true # volume 额外的选项, 在创建卷时禁用从容器复制数据 - type: bind # volume 模式只指定容器路径即可, 宿主机路径随机生成; bind 需要指定容器和数据机的映射路径 source: ./static target: /opt/app/static read_only: true # 设置文件系统为只读文件系统 volumes: mydata: # 定义在 volume, 可在所有服务中调用restart # 定义容器重启策略(在使用 swarm 部署时将忽略该选项, 在 swarm 使用 restart_policy 代替 restart) no # 禁止自动重启容器(默认) always # 无论如何容器都会重启 on-failure # 当出现 on-failure 报错时, 容器重新启动其他选项： domainname, hostname, ipc, mac_address, privileged, read_only, shm_size, stdin_open, tty, user, working_dir 上面这些选项都只接受单个值和 docker run 的对应参数类似对于值为时间的可接受的值： 2.5s 10s 1m30s 2h32m 5h34m56s 时间单位: us, ms, s, m， h对于值为大小的可接受的值： 2b 1024kb 2048k 300m 1gb 单位: b, k, m, g 或者 kb, mb, gbnetworks # 定义 networks 信息driver # 指定网络模式, 大多数情况下, 它 bridge 于单个主机和 overlay Swarm 上 bridge # Docker 默认使用 bridge 连接单个主机上的网络 overlay # overlay 驱动程序创建一个跨多个节点命名的网络 host # 共享主机网络名称空间(等同于 docker run --net=host) none # 等同于 docker run --net=nonedriver_opts # v3.2以上版本, 传递给驱动程序的参数, 这些参数取决于驱动程序attachable # driver 为 overlay 时使用, 如果设置为 true 则除了服务之外，独立容器也可以附加到该网络; 如果独立容器连接到该网络，则它可以与其他 Docker 守护进程连接到的该网络的服务和独立容器进行通信ipam # 自定义 IPAM 配置. 这是一个具有多个属性的对象, 每个属性都是可选的 driver # IPAM 驱动程序, bridge 或者 default config # 配置项 subnet # CIDR格式的子网，表示该网络的网段external # 外部网络, 如果设置为 true 则 docker-compose up 不会尝试创建它, 如果它不存在则引发错误name # v3.5 以上版本, 为此网络设置名称","categories":[],"tags":[]},{"title":"升级Mac下node版本","slug":"升级Mac下node版本","date":"2020-11-15T10:04:42.000Z","updated":"2020-11-16T05:28:10.476Z","comments":true,"path":"paper/升级Mac下node版本/","link":"","permalink":"https://sangedon.cn/paper/升级Mac下node版本/","excerpt":"","text":"可通过 n 工具 或者 nvm 工具进行升级，具体方式如下 通过 n 工具升级 查看本机 nodejs 版本 1node -v 清除 nodejs 的缓存 1sudo npm cache clean -f 安装 nodejs 管理工具 n 工具，对，名字就叫 n 1sudo npm install -g n 安装最新稳定版本的 nodejs 1sudo n stable 查看本机 nodejs 版本，见步骤 1 更新 npm 到最新版 1sudo npm install npm@latest -g 验证 12345# 验证 node 版本node -v# 验证 npm 版本npm -v 通过 nvm 工具升级 nvm 安装 1curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.3/install.sh | bash 检查是否安装成功 1nvm --version 若不成功，执行 source ~/.bash_profile 即可，若还不成功，需配置nvm环境变量信息 安装 nodejs 12345# version字段为要安装的node版本nvm install version# 如要安装12.9.0nvm install 12.9.0 查看 nodejs 版本 1node -v 使用 nvm 管理 nodejs 版本 12345# 查看 nodejs 版本nvm list# 使用某个版本 nodejsnvm use 12.9.0","categories":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://sangedon.cn/categories/环境搭建/"}],"tags":[{"name":"Mac","slug":"Mac","permalink":"https://sangedon.cn/tags/Mac/"}]},{"title":"Gitee上使用Jenkins流水线搭建","slug":"Gitee上使用Jenkins流水线搭建","date":"2020-11-13T11:51:19.000Z","updated":"2020-11-16T05:15:36.372Z","comments":true,"path":"paper/Gitee上使用Jenkins流水线搭建/","link":"","permalink":"https://sangedon.cn/paper/Gitee上使用Jenkins流水线搭建/","excerpt":"","text":"Jenkins 安装 Jenkins使用docker-compose来部署安装，配置如下 123456789101112131415161718version: '3.7'service: jenkins: container_name: jenkins image: 'jenkinszh/jenkins-zh:lts' restart: always enviroment: - TZ=Asia/Shanghai ports: - '8088:8080' - '50000:50000' volume: - /opt/docker/jenkins/data:/var/jenkins_home - /var/run/docker.sock:/var/run/docker.sock - /usr/bin/docker:/usr/bin/docker - /usr/lib/x86_64-linux-gnu/libltdl.so.7:/usr/lib/x86_64-linux-gnu/libltdl.so.7 privileged: true user: root Gitee 插件安装 在线安装 前往 Manage Jenkins -&gt; Manage Plugins -&gt; Available 右侧 Filter 输入： Gitee 下方可选列表中勾选 Gitee（如列表中不存在 Gitee，则点击 Check now 更新插件列表） 点击 Download now and install after restart 手动安装 从 release 列表中进入最新发行版，下载对应的 XXX.hpi 文件 前往 Manage Jenkins -&gt; Manage Plugins -&gt; Advanced Upload Plugin File 中选择刚才下载的 XXX.hpi 点击 Upload 后续页面中勾选 Restart Jenkins when installation is complete and no jobs are running 插件配置添加 Gitee 链接配置 前往 Jenkins -&gt; Manage Jenkins -&gt; Configure System -&gt; Gitee Configuration -&gt; Gitee connections 在 Connection name 中输入 Gitee 或者你想要的名字 Gitee host URL 中输入 Gitee 完整 URL地址： https://gitee.com （Gitee 私有化客户输入部署的域名） Credentials 中如还未配置 Gitee APIV5 私人令牌，点击 Add - &gt;Jenkins Domain 选择 Global credentials Kind 选择 Gitee API Token Scope 选择你需要的范围 Gitee API Token 输入你的 Gitee 私人令牌，获取地址：https://gitee.com/profile/personal_access_tokens ID, Descripiton 中输入你想要的 ID 和描述即可。 Credentials 选择配置好的 Gitee APIV5 Token 点击 Advanced ，可配置是否忽略 SSL 错误（视您的Jenkins环境是否支持），并可设置链接测超时时间（视您的网络环境而定） 点击 Test Connection 测试链接是否成功，如失败请检查以上 3，5，6 步骤。 配置节点 前往 Jenkins -&gt; 系统管理 -&gt; 节点管理 -&gt; 新建节点，填写节点名称，选择固定节点，或着复制现有节点（如果有的话） 上一步点击确定之后进入配置页面，如下 配置完成后连接节点，当节点显示在线时即节点成功连上 创建流水线任务 前往 Jenkins -&gt; 新建任务， 填写任务名称后，选择创建自由风格的软件项目，点击确定，进入编辑页面 源码配置，如下 源码配置后简单的任务配置构建步骤即可，如下 运行任务，如下启动 如无问题，流水线创建成功！ 配置WebHook自动触发 Jenkins下webhook配置 Gitee 下Webhook 配置 测试","categories":[{"name":"Devops","slug":"Devops","permalink":"https://sangedon.cn/categories/Devops/"}],"tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://sangedon.cn/tags/jenkins/"}]},{"title":"redis 笔记","slug":"redis-笔记","date":"2020-10-23T04:54:38.000Z","updated":"2020-10-23T05:10:22.305Z","comments":true,"path":"paper/redis-笔记/","link":"","permalink":"https://sangedon.cn/paper/redis-笔记/","excerpt":"","text":"官方介绍中表示Redis是一种开放源代码（BSD许可）的内存中数据结构存储，用作数据库，缓存和消息代理。它支持多种数据结构，例如字符串，哈希表，列表，集合，带范围查询的排序集，位图，超级日志，带有半径查询和流的地理空间索引。Redis具有内置的复制，Lua脚本，LRU驱逐，事务和不同级别的磁盘持久性，并可以通过Redis Sentinel和Redis Cluster自动分区提供高可用性。 随着用户量增大，请求数量也在不断增大，导致数据库压力也不断增大 多台服务器之间数据不同步 不同服务器之间的锁不存在互斥性","categories":[{"name":"中间件","slug":"中间件","permalink":"https://sangedon.cn/categories/中间件/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://sangedon.cn/tags/缓存/"},{"name":"redis","slug":"redis","permalink":"https://sangedon.cn/tags/redis/"},{"name":"笔记","slug":"笔记","permalink":"https://sangedon.cn/tags/笔记/"}]},{"title":"Mysql知识点总结","slug":"Mysql知识点总结","date":"2020-10-22T13:26:50.000Z","updated":"2020-10-22T14:35:11.843Z","comments":true,"path":"paper/Mysql知识点总结/","link":"","permalink":"https://sangedon.cn/paper/Mysql知识点总结/","excerpt":"","text":"作者：贾不假 一、MySQL架构和其它数据库相比，MySQL有点与众不同，它的架构可以在多种不同场景中应用并发挥良好作用。主要体现在存储引擎的架构上，插件式的存储引擎架构将查询处理和其它的系统任务以及数据的存储提取相分离。这种架构可以根据业务的需求和实际需要选择合适的存储引擎。 连接层：最上层是一些客户端和连接服务。主要完成一些类似于连接处理、授权认证、及相关的安全方案。在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。 服务层：第二层服务层，主要完成大部分的核心服务功能， 包括查询解析、分析、优化、缓存、以及所有的内置函数，所有跨存储引擎的功能也都在这一层实现，包括触发器、存储过程、视图等 引擎层：第三层存储引擎层，存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信。不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取 存储层：第四层为数据存储层，主要是将数据存储在运行于该设备的文件系统之上，并完成与存储引擎的交互 画出 MySQL 架构图，这种变态问题都能问的出来 MySQL 的查询流程具体是？or 一条SQL语句在MySQL中如何执行的？ 客户端请求 —&gt; 连接器（验证用户身份，给予权限） —&gt; 查询缓存（存在缓存则直接返回，不存在则执行后续操作） —&gt; 分析器（对SQL进行词法分析和语法分析操作） —&gt; 优化器（主要对执行的sql优化选择最优的执行方案方法） —&gt; 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口） —&gt; 去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果） 说说MySQL有哪些存储引擎？都有哪些区别？ 二、存储引擎存储引擎是MySQL的组件，用于处理不同表类型的SQL操作。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能，使用不同的存储引擎，还可以获得特定的功能。 使用哪一种引擎可以灵活选择，一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求，使用合适的存储引擎，将会提高整个数据库的性能 。 MySQL服务器使用可插拔的存储引擎体系结构，可以从运行中的 MySQL 服务器加载或卸载存储引擎 。 查看存储引擎123456789101112-- 查看支持的存储引擎SHOW ENGINES-- 查看默认存储引擎SHOW VARIABLES LIKE &apos;storage_engine&apos;--查看具体某一个表所使用的存储引擎，这个默认存储引擎被修改了！show create table tablename--准确查看某个数据库中的某一表所使用的存储引擎show table status like &apos;tablename&apos;show table status from database where name=&quot;tablename&quot; 设置存储引擎12345678910-- 建表时指定存储引擎。默认的就是INNODB，不需要设置CREATE TABLE t1 (i INT) ENGINE = INNODB;CREATE TABLE t2 (i INT) ENGINE = CSV;CREATE TABLE t3 (i INT) ENGINE = MEMORY;-- 修改存储引擎ALTER TABLE t ENGINE = InnoDB;-- 修改默认存储引擎，也可以在配置文件my.cnf中修改默认引擎SET default_storage_engine=NDBCLUSTER; 默认情况下，每当 CREATE TABLE 或 ALTER TABLE 不能使用默认存储引擎时，都会生成一个警告。为了防止在所需的引擎不可用时出现令人困惑的意外行为，可以启用 NO_ENGINE_SUBSTITUTION SQL 模式。如果所需的引擎不可用，则此设置将产生错误而不是警告，并且不会创建或更改表 存储引擎对比常见的存储引擎就 InnoDB、MyISAM、Memory、NDB。 InnoDB 现在是 MySQL 默认的存储引擎，支持事务、行级锁定和外键 文件存储结构对比在 MySQL中建立任何一张数据表，在其数据目录对应的数据库目录下都有对应表的 .frm 文件，.frm 文件是用来保存每个数据表的元数据(meta)信息，包括表结构的定义等，与数据库存储引擎无关，也就是任何存储引擎的数据表都必须有.frm文件，命名方式为 数据表名.frm，如user.frm。 查看MySQL 数据保存在哪里：show variables like &#39;data%&#39; MyISAM 物理文件结构为： .frm文件：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等 .MYD (MYData) 文件：MyISAM 存储引擎专用，用于存储MyISAM 表的数据 .MYI (MYIndex)文件：MyISAM 存储引擎专用，用于存储MyISAM 表的索引相关信息 InnoDB 物理文件结构为： .frm 文件：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等 .ibd 文件或 .ibdata 文件： 这两种文件都是存放 InnoDB 数据的文件，之所以有两种文件形式存放 InnoDB 的数据，是因为 InnoDB 的数据存储方式能够通过配置来决定是使用共享表空间存放存储数据，还是用独享表空间存放存储数据。 独享表空间存储方式使用.ibd文件，并且每个表一个.ibd文件 共享表空间存储方式使用.ibdata文件，所有表共同使用一个.ibdata文件（或多个，可自己配置） ps：正经公司，这些都有专业运维去做，数据备份、恢复啥的，让我一个 Javaer 搞这的话，加钱不？ 面试这么回答 InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一； InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败； InnoDB 是聚簇索引，MyISAM 是非聚簇索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 InnoDB 不保存表的具体行数，执行select count(*) from table 时需要全表扫描。而 MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快； InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一； 对比项 MyISAM InnoDB 主外键 不支持 支持 事务 不支持 支持 行表锁 表锁，即使操作一条记录也会锁住整个表，不适合高并发的操作 行锁,操作时只锁某一行，不对其它行有影响，适合高并发的操作 缓存 只缓存索引，不缓存真实数据 不仅缓存索引还要缓存真实数据，对内存要求较高，而且内存大小对性能有决定性的影响 表空间 小 大 关注点 性能 事务 默认安装 是 是 一张表，里面有ID自增主键，当insert了17条记录之后，删除了第15,16,17条记录，再把Mysql重启，再insert一条记录，这条记录的ID是18还是15 ？ 如果表的类型是MyISAM，那么是18。因为MyISAM表会把自增主键的最大ID 记录到数据文件中，重启MySQL自增主键的最大ID也不会丢失； 如果表的类型是InnoDB，那么是15。因为InnoDB 表只是把自增主键的最大ID记录到内存中，所以重启数据库或对表进行OPTION操作，都会导致最大ID丢失。 哪个存储引擎执行 select count(*) 更快，为什么? MyISAM更快，因为MyISAM内部维护了一个计数器，可以直接调取。 在 MyISAM 存储引擎中，把表的总行数存储在磁盘上，当执行 select count(*) from t 时，直接返回总数据。 在 InnoDB 存储引擎中，跟 MyISAM 不一样，没有将总行数存储在磁盘上，当执行 select count(*) from t 时，会先把数据读出来，一行一行的累加，最后返回总数量。 InnoDB 中 count(*) 语句是在执行的时候，全表扫描统计总数量，所以当数据越来越大时，语句就越来越耗时了，为什么 InnoDB 引擎不像 MyISAM 引擎一样，将总行数存储到磁盘上？这跟 InnoDB 的事务特性有关，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。 三、数据类型主要包括以下五大类： 整数类型：BIT、BOOL、TINY INT、SMALL INT、MEDIUM INT、 INT、 BIG INT 浮点数类型：FLOAT、DOUBLE、DECIMAL 字符串类型：CHAR、VARCHAR、TINY TEXT、TEXT、MEDIUM TEXT、LONGTEXT、TINY BLOB、BLOB、MEDIUM BLOB、LONG BLOB 日期类型：Date、DateTime、TimeStamp、Time、Year 其他数据类型：BINARY、VARBINARY、ENUM、SET、Geometry、Point、MultiPoint、LineString、MultiLineString、Polygon、GeometryCollection等 CHAR 和 VARCHAR 的区别？ char是固定长度，varchar长度可变： char(n) 和 varchar(n) 中括号中 n 代表字符的个数，并不代表字节个数，比如 CHAR(30) 就可以存储 30 个字符。 存储时，前者不管实际存储数据的长度，直接按 char 规定的长度分配存储空间；而后者会根据实际存储的数据分配最终的存储空间 相同点： char(n)，varchar(n)中的n都代表字符的个数 超过char，varchar最大长度n的限制后，字符串会被截断。 不同点： char不论实际存储的字符数都会占用n个字符的空间，而varchar只会占用实际字符应该占用的字节空间加1（实际长度length，0&lt;=length&lt;255）或加2（length&gt;255）。因为varchar保存数据时除了要保存字符串之外还会加一个字节来记录长度（如果列声明长度大于255则使用两个字节来保存长度）。 能存储的最大空间限制不一样：char的存储上限为255字节。 char在存储时会截断尾部的空格，而varchar不会。 char是适合存储很短的、一般固定长度的字符串。例如，char非常适合存储密码的MD5值，因为这是一个定长的值。对于非常短的列，char比varchar在存储空间上也更有效率。 列的字符串类型可以是什么？ 字符串类型是：SET、BLOB、ENUM、CHAR、TEXT、VARCHAR BLOB和TEXT有什么区别？ BLOB是一个二进制对象，可以容纳可变数量的数据。有四种类型的BLOB：TINYBLOB、BLOB、MEDIUMBLO和 LONGBLOB TEXT是一个不区分大小写的BLOB。四种TEXT类型：TINYTEXT、TEXT、MEDIUMTEXT 和 LONGTEXT。 BLOB 保存二进制数据，TEXT 保存字符数据。 四、索引 说说你对 MySQL 索引的理解？ 数据库索引的原理，为什么要用 B+树，为什么不用二叉树？ 聚集索引与非聚集索引的区别？ InnoDB引擎中的索引策略，了解过吗？ 创建索引的方式有哪些？ 聚簇索引/非聚簇索引，mysql索引底层实现，为什么不用B-tree，为什么不用hash，叶子结点存放的是数据还是指向数据的内存地址，使用索引需要注意的几个地方？ MYSQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构，所以说索引的本质是：数据结构 索引的目的在于提高查询效率，可以类比字典、 火车站的车次表、图书的目录等 。 可以简单的理解为“排好序的快速查找数据结构”，数据本身之外，数据库还维护者一个满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。下图是一种可能的索引方式示例。 左边的数据表，一共有两列七条记录，最左边的是数据记录的物理地址 为了加快Col2的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值，和一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找在一定的复杂度内获取到对应的数据，从而快速检索出符合条件的记录。 索引本身也很大，不可能全部存储在内存中，一般以索引文件的形式存储在磁盘上 平常说的索引，没有特别指明的话，就是B+树（多路搜索树，不一定是二叉树）结构组织的索引。其中聚集索引，次要索引，覆盖索引，复合索引，前缀索引，唯一索引默认都是使用B+树索引，统称索引。此外还有哈希索引等。 基本语法： 创建： 创建索引：CREATE [UNIQUE] INDEX indexName ON mytable(username(length)); 如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB和TEXT类型，必须指定 length。 修改表结构(添加索引)：ALTER table tableName ADD [UNIQUE] INDEX indexName(columnName) 删除：DROP INDEX [indexName] ON mytable; 查看：SHOW INDEX FROM table_name\\G –可以通过添加 \\G 来格式化输出信息。 使用ALERT命令 ALTER TABLE tbl_name ADD PRIMARY KEY (column_list): 该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。 ALTER TABLE tbl_name ADD UNIQUE index_name (column_list 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。 ALTER TABLE tbl_name ADD INDEX index_name (column_list) 添加普通索引，索引值可出现多次。 ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list)该语句指定了索引为 FULLTEXT ，用于全文索引。 优势 提高数据检索效率，降低数据库IO成本 降低数据排序的成本，降低CPU的消耗 劣势 索引也是一张表，保存了主键和索引字段，并指向实体表的记录，所以也需要占用内存 虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。 因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段， 都会调整因为更新所带来的键值变化后的索引信息 MySQL索引分类数据结构角度 B+树索引 Hash索引 Full-Text全文索引 R-Tree索引 从物理存储角度 聚集索引（clustered index） 非聚集索引（non-clustered index），也叫辅助索引（secondary index） 聚集索引和非聚集索引都是B+树结构 从逻辑角度 主键索引：主键索引是一种特殊的唯一索引，不允许有空值 普通索引或者单列索引：每个索引只包含单个列，一个表可以有多个单列索引 多列索引（复合索引、联合索引）：复合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用复合索引时遵循最左前缀集合 唯一索引或者非唯一索引 空间索引：空间索引是对空间数据类型的字段建立的索引，MYSQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING、POLYGON。 MYSQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引。创建空间索引的列，必须将其声明为NOT NULL，空间索引只能在存储引擎为MYISAM的表中创建 为什么MySQL 索引中用B+tree，不用B-tree 或者其他树，为什么不用 Hash 索引 聚簇索引/非聚簇索引，MySQL 索引底层实现，叶子结点存放的是数据还是指向数据的内存地址，使用索引需要注意的几个地方？ 使用索引查询一定能提高查询的性能吗？为什么? MySQL索引结构首先要明白索引（index）是在存储引擎（storage engine）层面实现的，而不是server层面。不是所有的存储引擎都支持所有的索引类型。即使多个存储引擎支持某一索引类型，它们的实现和行为也可能有所差别。 B+Tree索引MyISAM 和 InnoDB 存储引擎，都使用 B+Tree的数据结构，它相对与 B-Tree结构，所有的数据都存放在叶子节点上，且把叶子节点通过指针连接到一起，形成了一条数据链表，以加快相邻数据的检索效率。 先了解下 B-Tree 和 B+Tree 的区别 B-TreeB-Tree是为磁盘等外存储设备设计的一种平衡查找树。 系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。 InnoDB 存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。InnoDB 存储引擎中默认每个页的大小为16KB，可通过参数 innodb_page_size 将页的大小设置为 4K、8K、16K，在 MySQL 中可通过如下命令查看页的大小：show variables like &#39;innodb_page_size&#39;; 而系统一个磁盘块的存储空间往往没有这么大，因此 InnoDB 每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小 16KB。InnoDB 在把磁盘数据读入到磁盘时会以页为基本单位，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘I/O次数，提高查询效率。 B-Tree 结构的数据可以让系统高效的找到数据所在的磁盘块。为了描述 B-Tree，首先定义一条记录为一个二元组[key, data] ，key为记录的键值，对应表中的主键值，data 为一行记录中除主键外的数据。对于不同的记录，key值互不相同。 一棵m阶的B-Tree有如下特性： 每个节点最多有m个孩子 除了根节点和叶子节点外，其它每个节点至少有Ceil(m/2)个孩子。 若根节点不是叶子节点，则至少有2个孩子 所有叶子节点都在同一层，且不包含其它关键字信息 每个非终端节点包含n个关键字信息（P0,P1,…Pn, k1,…kn） 关键字的个数n满足：ceil(m/2)-1 &lt;= n &lt;= m-1 ki(i=1,…n)为关键字，且关键字升序排序 Pi(i=1,…n)为指向子树根节点的指针。P(i-1)指向的子树的所有节点关键字均小于ki，但都大于k(i-1) B-Tree 中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个 3 阶的 B-Tree： 每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的关键字和三个指向子树根节点的指针，指针存储的是子节点所在磁盘块的地址。两个关键词划分成的三个范围域对应三个指针指向的子树的数据的范围域。以根节点为例，关键字为17和35，P1指针指向的子树的数据范围为小于17，P2指针指向的子树的数据范围为17~35，P3指针指向的子树的数据范围为大于35。 模拟查找关键字29的过程： 根据根节点找到磁盘块1，读入内存。【磁盘I/O操作第1次】 比较关键字29在区间（17,35），找到磁盘块1的指针P2。 根据P2指针找到磁盘块3，读入内存。【磁盘I/O操作第2次】 比较关键字29在区间（26,30），找到磁盘块3的指针P2。 根据P2指针找到磁盘块8，读入内存。【磁盘I/O操作第3次】 在磁盘块8中的关键字列表中找到关键字29。 分析上面过程，发现需要3次磁盘I/O操作，和3次内存查找操作。由于内存中的关键字是一个有序表结构，可以利用二分法查找提高效率。而3次磁盘I/O操作是影响整个B-Tree查找效率的决定因素。B-Tree相对于AVLTree缩减了节点个数，使每次磁盘I/O取到内存的数据都发挥了作用，从而提高了查询效率。 B+TreeB+Tree 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构，InnoDB 存储引擎就是用 B+Tree 实现其索引结构。 从上一节中的B-Tree结构图中可以看到每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度。 B+Tree相对于B-Tree有几点不同： 非叶子节点只存储键值信息； 所有叶子节点之间都有一个链指针； 数据记录都存放在叶子节点中 将上一节中的B-Tree优化，由于B+Tree的非叶子节点只存储键值信息，假设每个磁盘块能存储4个键值及指针信息，则变成B+Tree后其结构如下图所示： 通常在B+Tree上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环结构。因此可以对B+Tree进行两种查找运算：一种是对于主键的范围查找和分页查找，另一种是从根节点开始，进行随机查找。 可能上面例子中只有22条数据记录，看不出B+Tree的优点，下面做一个推算： InnoDB存储引擎中页的大小为16KB，一般表的主键类型为INT（占用4个字节）或BIGINT（占用8个字节），指针类型也一般为4或8个字节，也就是说一个页（B+Tree中的一个节点）中大概存储16KB/(8B+8B)=1K个键值（因为是估值，为方便计算，这里的K取值为10^3）。也就是说一个深度为3的B+Tree索引可以维护10^3 10^3 10^3 = 10亿 条记录。 实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree的高度一般都在2-4层。MySQL的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作。 B+Tree性质 通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。 当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。 MyISAM主键索引与辅助索引的结构MyISAM引擎的索引文件和数据文件是分离的。MyISAM引擎索引结构的叶子节点的数据域，存放的并不是实际的数据记录，而是数据记录的地址。索引文件与数据文件分离，这样的索引称为”非聚簇索引“。MyISAM的主索引与辅助索引区别并不大，只是主键索引不能有重复的关键字。 在MyISAM中，索引（含叶子节点）存放在单独的.myi文件中，叶子节点存放的是数据的物理地址偏移量（通过偏移量访问就是随机访问，速度很快）。 主索引是指主键索引，键值不可能重复；辅助索引则是普通索引，键值可能重复。 通过索引查找数据的流程：先从索引文件中查找到索引节点，从中拿到数据的文件指针，再到数据文件中通过文件指针定位了具体的数据。辅助索引类似。 InnoDB主键索引与辅助索引的结构InnoDB引擎索引结构的叶子节点的数据域，存放的就是实际的数据记录（对于主索引，此处会存放表中所有的数据记录；对于辅助索引此处会引用主键，检索的时候通过主键到主键索引中找到对应数据行），或者说，InnoDB的数据文件本身就是主键索引文件，这样的索引被称为”“聚簇索引”，一个表只能有一个聚簇索引。 主键索引：我们知道InnoDB索引是聚集索引，它的索引和数据是存入同一个.idb文件中的，因此它的索引结构是在同一个树节点中同时存放索引和数据，如下图中最底层的叶子节点有三行数据，对应于数据表中的id、stu_id、name数据项。 在Innodb中，索引分叶子节点和非叶子节点，非叶子节点就像新华字典的目录，单独存放在索引段中，叶子节点则是顺序排列的，在数据段中。Innodb的数据文件可以按照表来切分（只需要开启innodb_file_per_table)，切分后存放在xxx.ibd中，默认不切分，存放在xxx.ibdata中。 辅助（非主键）索引：这次我们以示例中学生表中的name列建立辅助索引，它的索引结构跟主键索引的结构有很大差别，在最底层的叶子结点有两行数据，第一行的字符串是辅助索引，按照ASCII码进行排序，第二行的整数是主键的值。 这就意味着，对name列进行条件搜索，需要两个步骤： ① 在辅助索引上检索name，到达其叶子节点获取对应的主键； ② 使用主键在主索引上再进行对应的检索操作 这也就是所谓的“回表查询” InnoDB 索引结构需要注意的点 数据文件本身就是索引文件 表数据文件本身就是按 B+Tree 组织的一个索引结构文件 聚集索引中叶节点包含了完整的数据记录 InnoDB 表必须要有主键，并且推荐使用整型自增主键 正如我们上面介绍 InnoDB 存储结构，索引与数据是共同存储的，不管是主键索引还是辅助索引，在查找时都是通过先查找到索引节点才能拿到相对应的数据，如果我们在设计表结构时没有显式指定索引列的话，MySQL 会从表中选择数据不重复的列建立索引，如果没有符合的列，则 MySQL 自动为 InnoDB 表生成一个隐含字段作为主键，并且这个字段长度为6个字节，类型为整型。 那为什么推荐使用整型自增主键而不是选择UUID？ UUID是字符串，比整型消耗更多的存储空间； 在B+树中进行查找时需要跟经过的节点值比较大小，整型数据的比较运算比字符串更快速； 自增的整型索引在磁盘中会连续存储，在读取一页数据时也是连续；UUID是随机产生的，读取的上下两行数据存储是分散的，不适合执行where id &gt; 5 &amp;&amp; id &lt; 20的条件查询语句。 在插入或删除数据时，整型自增主键会在叶子结点的末尾建立新的叶子节点，不会破坏左侧子树的结构；UUID主键很容易出现这样的情况，B+树为了维持自身的特性，有可能会进行结构的重构，消耗更多的时间。 为什么非主键索引结构叶子节点存储的是主键值？ 保证数据一致性和节省存储空间，可以这么理解：商城系统订单表会存储一个用户ID作为关联外键，而不推荐存储完整的用户信息，因为当我们用户表中的信息（真实名称、手机号、收货地址···）修改后，不需要再次维护订单表的用户数据，同时也节省了存储空间。 Hash索引 主要就是通过Hash算法（常见的Hash算法有直接定址法、平方取中法、折叠法、除数取余法、随机数法），将数据库字段数据转换成定长的Hash值，与这条数据的行指针一并存入Hash表的对应位置；如果发生Hash碰撞（两个不同关键字的Hash值相同），则在对应Hash键下以链表形式存储。 检索算法：在检索查询时，就再次对待查关键字再次执行相同的Hash算法，得到Hash值，到对应Hash表对应位置取出数据即可，如果发生Hash碰撞，则需要在取值时进行筛选。目前使用Hash索引的数据库并不多，主要有Memory等。 MySQL目前有Memory引擎和NDB引擎支持Hash索引。 full-text全文索引 全文索引也是MyISAM的一种特殊索引类型，主要用于全文索引，InnoDB从MYSQL5.6版本提供对全文索引的支持。 它用于替代效率较低的LIKE模糊匹配操作，而且可以通过多字段组合的全文索引一次性全模糊匹配多个字段。 同样使用B-Tree存放索引数据，但使用的是特定的算法，将字段数据分割后再进行索引（一般每4个字节一次分割），索引文件存储的是分割前的索引字符串集合，与分割后的索引信息，对应Btree结构的节点存储的是分割后的词信息以及它在分割前的索引字符串集合中的位置。 R-Tree空间索引空间索引是MyISAM的一种特殊索引类型，主要用于地理空间数据类型 为什么Mysql索引要用B+树不是B树？ 用B+树不用B树考虑的是IO对性能的影响，B树的每个节点都存储数据，而B+树只有叶子节点才存储数据，所以查找相同数据量的情况下，B树的高度更高，IO更频繁。数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存了，只能逐一加载每一个磁盘页（对应索引树的节点）。其中在MySQL底层对B+树进行进一步优化：在叶子节点中是双向链表，且在链表的头结点和尾节点也是循环指向的。 面试官：为何不采用Hash方式？ 因为Hash索引底层是哈希表，哈希表是一种以key-value存储数据的结构，所以多个数据在存储关系上是完全没有任何顺序关系的，所以，对于区间查询是无法直接通过索引查询的，就需要全表扫描。所以，哈希索引只适用于等值查询的场景。而B+ Tree是一种多路平衡查询树，所以他的节点是天然有序的（左子节点小于父节点、父节点小于右子节点），所以对于范围查询的时候不需要做全表扫描。 哈希索引不支持多列联合索引的最左匹配规则，如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题。 哪些情况需要创建索引 主键自动建立唯一索引 频繁作为查询条件的字段 查询中与其他表关联的字段，外键关系建立索引 单键/组合索引的选择问题，高并发下倾向创建组合索引 查询中排序的字段，排序字段通过索引访问大幅提高排序速度 查询中统计或分组字段 哪些情况不要创建索引 表记录太少 经常增删改的表 数据重复且分布均匀的表字段，只应该为最经常查询和最经常排序的数据列建立索引（如果某个数据类包含太多的重复数据，建立索引没有太大意义） 频繁更新的字段不适合创建索引（会加重IO负担） where条件里用不到的字段不创建索引 MySQL高效索引覆盖索引（Covering Index）,或者叫索引覆盖， 也就是平时所说的不需要回表操作 就是select的数据列只用从索引中就能够取得，不必读取数据行，MySQL可以利用索引返回select列表中的字段，而不必根据索引再次读取数据文件，换句话说查询列要被所建的索引覆盖。 索引是高效找到行的一个方法，但是一般数据库也能使用索引找到一个列的数据，因此它不必读取整个行。毕竟索引叶子节点存储了它们索引的数据，当能通过读取索引就可以得到想要的数据，那就不需要读取行了。一个索引包含（覆盖）满足查询结果的数据就叫做覆盖索引。 判断标准 使用explain，可以通过输出的extra列来判断，对于一个索引覆盖查询，显示为using index，MySQL查询优化器在执行查询前会决定是否有索引覆盖查询 五、MySQL查询 count(*) 和 count(1)和count(列名)区别 ps：这道题说法有点多 执行效果上： count(*)包括了所有的列，相当于行数，在统计结果的时候，不会忽略列值为NULL count(1)包括了所有列，用1代表代码行，在统计结果的时候，不会忽略列值为NULL count(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。 执行效率上： 列名为主键，count(列名)会比count(1)快 列名不为主键，count(1)会比count(列名)快 如果表多个列并且没有主键，则 count(1) 的执行效率优于 count(*) 如果有主键，则 select count（主键）的执行效率是最优的 如果表只有一个字段，则 select count(*) 最优。 MySQL中 in和 exists 的区别？ exists：exists对外表用loop逐条查询，每次查询都会查看exists的条件语句，当exists里的条件语句能够返回记录行时（无论记录行是的多少，只要能返回），条件就为真，返回当前loop到的这条记录；反之，如果exists里的条件语句不能返回记录行，则当前loop到的这条记录被丢弃，exists的条件就像一个bool条件，当能返回结果集则为true，不能返回结果集则为false in：in查询相当于多个or条件的叠加 12SELECT * FROM A WHERE A.id IN (SELECT id FROM B);SELECT * FROM A WHERE EXISTS (SELECT * from B WHERE B.id = A.id); 如果查询的两个表大小相当，那么用in和exists差别不大。 如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in： UNION和UNION ALL的区别? UNION和UNION ALL都是将两个结果集合并为一个，两个要联合的SQL语句 字段个数必须一样，而且字段类型要“相容”（一致）； UNION在进行表连接后会筛选掉重复的数据记录（效率较低），而UNION ALL则不会去掉重复的数据记录； UNION会按照字段的顺序进行排序，而UNION ALL只是简单的将两个结果合并就返回； SQL执行顺序 手写 12345678SELECT DISTINCT &lt;select_list&gt;FROM &lt;left_table&gt; &lt;join_type&gt;JOIN &lt;right_table&gt; ON &lt;join_condition&gt;WHERE &lt;where_condition&gt;GROUP BY &lt;group_by_list&gt;HAVING &lt;having_condition&gt;ORDER BY &lt;order_by_condition&gt;LIMIT &lt;limit_number&gt; 机读 12345678910FROM &lt;left_table&gt;ON &lt;join_condition&gt;&lt;join_type&gt; JOIN &lt;right_table&gt; WHERE &lt;where_condition&gt;GROUP BY &lt;group_by_list&gt;HAVING &lt;having_condition&gt;SELECTDISTINCT &lt;select_list&gt;ORDER BY &lt;order_by_condition&gt;LIMIT &lt;limit_number&gt; 总结 mysql 的内连接、左连接、右连接有什么区别？ 什么是内连接、外连接、交叉连接、笛卡尔积呢？ Join图 六、MySQL 事务 事务的隔离级别有哪些？MySQL的默认隔离级别是什么？ 什么是幻读，脏读，不可重复读呢？ MySQL事务的四大特性以及实现原理 MVCC熟悉吗，它的底层原理？ MySQL 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你即需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等，这样，这些数据库操作语句就构成一个事务！ ACID — 事务基本要素 事务是由一组SQL语句组成的逻辑处理单元，具有4个属性，通常简称为事务的ACID属性。 A (Atomicity) 原子性：整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样 C (Consistency) 一致性：在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏 I (Isolation)隔离性：一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰 D (Durability) 持久性：在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚 并发事务处理带来的问题 更新丢失（Lost Update)： 事务A和事务B选择同一行，然后基于最初选定的值更新该行时，由于两个事务都不知道彼此的存在，就会发生丢失更新问题 脏读(Dirty Reads)：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据 不可重复读（Non-Repeatable Reads)：事务 A 多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。 幻读（Phantom Reads)：幻读与不可重复读类似。它发生在一个事务A读取了几行数据，接着另一个并发事务B插入了一些数据时。在随后的查询中，事务A就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 幻读和不可重复读的区别： 不可重复读的重点是修改：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改） 幻读的重点在于新增或者删除：在同一事务中，同样的条件,，第一次和第二次读出来的记录数不一样。（因为中间有其他事务提交了插入/删除） 并发事务处理带来的问题的解决办法： “更新丢失”通常是应该完全避免的。但防止更新丢失，并不能单靠数据库事务控制器来解决，需要应用程序对要更新的数据加必要的锁来解决，因此，防止更新丢失应该是应用的责任。 “脏读” 、 “不可重复读”和“幻读” ，其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决： 一种是加锁：在读取数据前，对其加锁，阻止其他事务对数据进行修改。 另一种是数据多版本并发控制（MultiVersion Concurrency Control，简称 MVCC 或 MCC），也称为多版本数据库：不用加任何锁， 通过一定机制生成一个数据请求时间点的一致性数据快照 （Snapshot)， 并用这个快照来提供一定级别 （语句级或事务级） 的一致性读取。从用户的角度来看，好象是数据库可以提供同一数据的多个版本。 事务隔离级别数据库事务的隔离级别有4种，由低到高分别为 READ-UNCOMMITTED(读未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 查看当前数据库的事务隔离级别： 1show variables like &apos;tx_isolation&apos; 下面通过事例一一阐述在事务的并发操作中可能会出现脏读，不可重复读，幻读和事务隔离级别的联系。 数据库的事务隔离越严格，并发副作用越小，但付出的代价就越大，因为事务隔离实质上就是使事务在一定程度上“串行化”进行，这显然与“并发”是矛盾的。同时，不同的应用对读一致性和事务隔离程度的要求也是不同的，比如许多应用对“不可重复读”和“幻读”并不敏感，可能更关心数据并发访问的能力。 Read uncommitted读未提交，就是一个事务可以读取另一个未提交事务的数据。 事例：老板要给程序员发工资，程序员的工资是3.6万/月。但是发工资时老板不小心按错了数字，按成3.9万/月，该钱已经打到程序员的户口，但是事务还没有提交，就在这时，程序员去查看自己这个月的工资，发现比往常多了3千元，以为涨工资了非常高兴。但是老板及时发现了不对，马上回滚差点就提交了的事务，将数字改成3.6万再提交。 分析：实际程序员这个月的工资还是3.6万，但是程序员看到的是3.9万。他看到的是老板还没提交事务时的数据。这就是脏读。 那怎么解决脏读呢？Read committed！读提交，能解决脏读问题。 Read committed读提交，顾名思义，就是一个事务要等另一个事务提交后才能读取数据。 事例：程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他埋单时（程序员事务开启），收费系统事先检测到他的卡里有3.6万，就在这个时候！！程序员的妻子要把钱全部转出充当家用，并提交。当收费系统准备扣款时，再检测卡里的金额，发现已经没钱了（第二次检测金额当然要等待妻子转出金额事务提交完）。程序员就会很郁闷，明明卡里是有钱的… 分析：这就是读提交，若有事务对数据进行更新（UPDATE）操作时，读操作事务要等待这个更新操作事务提交后才能读取数据，可以解决脏读问题。但在这个事例中，出现了一个事务范围内两个相同的查询却返回了不同数据，这就是不可重复读。 那怎么解决可能的不可重复读问题？Repeatable read ！ Repeatable read重复读，就是在开始读取数据（事务开启）时，不再允许修改操作。 MySQL的默认事务隔离级别 事例：程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他埋单时（事务开启，不允许其他事务的UPDATE修改操作），收费系统事先检测到他的卡里有3.6万。这个时候他的妻子不能转出金额了。接下来收费系统就可以扣款了。 分析：重复读可以解决不可重复读问题。写到这里，应该明白的一点就是，不可重复读对应的是修改，即UPDATE操作。但是可能还会有幻读问题。因为幻读问题对应的是插入INSERT操作，而不是UPDATE操作。 什么时候会出现幻读？ 事例：程序员某一天去消费，花了2千元，然后他的妻子去查看他今天的消费记录（全表扫描FTS，妻子事务开启），看到确实是花了2千元，就在这个时候，程序员花了1万买了一部电脑，即新增INSERT了一条消费记录，并提交。当妻子打印程序员的消费记录清单时（妻子事务提交），发现花了1.2万元，似乎出现了幻觉，这就是幻读。 那怎么解决幻读问题？Serializable！ Serializable 序列化Serializable 是最高的事务隔离级别，在该级别下，事务串行化顺序执行，可以避免脏读、不可重复读与幻读。简单来说，Serializable会在读取的每一行数据上都加锁，所以可能导致大量的超时和锁争用问题。这种事务隔离级别效率低下，比较耗数据库性能，一般不使用。 比较 事务隔离级别 读数据一致性 脏读 不可重复读 幻读 读未提交（read-uncommitted） 最低级被，只能保证不读取物理上损坏的数据 是 是 是 读已提交（read-committed） 语句级 否 是 是 可重复读（repeatable-read） 事务级 否 否 是 串行化（serializable） 最高级别，事务级 否 否 否 需要说明的是，事务隔离级别和数据访问的并发性是对立的，事务隔离级别越高并发性就越差。所以要根据具体的应用来确定合适的事务隔离级别，这个地方没有万能的原则。 MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）。我们可以通过SELECT @@tx_isolation;命令来查看，MySQL 8.0 该命令改为SELECT @@transaction_isolation; 这里需要注意的是：与 SQL 标准不同的地方在于InnoDB 存储引擎在 REPEATABLE-READ（可重读）事务隔离级别下使用的是Next-Key Lock 算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server)是不同的。所以说InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 SERIALIZABLE(可串行化)隔离级别，而且保留了比较好的并发性能。 因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是READ-COMMITTED(读已提交):，但是你要知道的是InnoDB 存储引擎默认使用 REPEATABLE-READ（可重读）并不会有任何性能损失。 MVCC 多版本并发控制MySQL的大多数事务型存储引擎实现都不是简单的行级锁。基于提升并发性考虑，一般都同时实现了多版本并发控制（MVCC），包括Oracle、PostgreSQL。只是实现机制各不相同。 可以认为 MVCC 是行级锁的一个变种，但它在很多情况下避免了加锁操作，因此开销更低。虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只是锁定必要的行。 MVCC 的实现是通过保存数据在某个时间点的快照来实现的。也就是说不管需要执行多长时间，每个事物看到的数据都是一致的。 典型的MVCC实现方式，分为乐观（optimistic）并发控制和悲观（pressimistic）并发控制。下边通过 InnoDB的简化版行为来说明 MVCC 是如何工作的。 InnoDB 的 MVCC，是通过在每行记录后面保存两个隐藏的列来实现。这两个列，一个保存了行的创建时间，一个保存行的过期时间（删除时间）。当然存储的并不是真实的时间，而是系统版本号（system version number）。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。 REPEATABLE READ（可重读）隔离级别下MVCC如何工作： SELECT InnoDB会根据以下两个条件检查每行记录： InnoDB只查找版本早于当前事务版本的数据行，这样可以确保事务读取的行，要么是在开始事务之前已经存在要么是事务自身插入或者修改过的 行的删除版本号要么未定义，要么大于当前事务版本号，这样可以确保事务读取到的行在事务开始之前未被删除 只有符合上述两个条件的才会被查询出来 INSERT：InnoDB为新插入的每一行保存当前系统版本号作为行版本号 DELETE：InnoDB为删除的每一行保存当前系统版本号作为行删除标识 UPDATE：InnoDB为插入的一行新纪录保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为删除标识 保存这两个额外系统版本号，使大多数操作都不用加锁。使数据操作简单，性能很好，并且也能保证只会读取到符合要求的行。不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作和一些额外的维护工作。 MVCC 只在 COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作。 事务日志InnoDB 使用日志来减少提交事务时的开销。因为日志中已经记录了事务，就无须在每个事务提交时把缓冲池的脏块刷新(flush)到磁盘中。 事务修改的数据和索引通常会映射到表空间的随机位置，所以刷新这些变更到磁盘需要很多随机 IO。 InnoDB 假设使用常规磁盘，随机IO比顺序IO昂贵得多，因为一个IO请求需要时间把磁头移到正确的位置，然后等待磁盘上读出需要的部分，再转到开始位置。 InnoDB 用日志把随机IO变成顺序IO。一旦日志安全写到磁盘，事务就持久化了，即使断电了，InnoDB可以重放日志并且恢复已经提交的事务。 InnoDB 使用一个后台线程智能地刷新这些变更到数据文件。这个线程可以批量组合写入，使得数据写入更顺序，以提高效率。 事务日志可以帮助提高事务效率： 使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘。 事务日志采用的是追加的方式，因此写日志的操作是磁盘上一小块区域内的顺序I/O，而不像随机I/O需要在磁盘的多个地方移动磁头，所以采用事务日志的方式相对来说要快得多。 事务日志持久以后，内存中被修改的数据在后台可以慢慢刷回到磁盘。 如果数据的修改已经记录到事务日志并持久化，但数据本身没有写回到磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这一部分修改的数据。 目前来说，大多数存储引擎都是这样实现的，我们通常称之为预写式日志（Write-Ahead Logging），修改数据需要写两次磁盘。 事务的实现事务的实现是基于数据库的存储引擎。不同的存储引擎对事务的支持程度不一样。MySQL 中支持事务的存储引擎有 InnoDB 和 NDB。 事务的实现就是如何实现ACID特性。 事务的隔离性是通过锁实现，而事务的原子性、一致性和持久性则是通过事务日志实现 。 事务是如何通过日志来实现的，说得越深入越好。 事务日志包括：重做日志redo和回滚日志undo redo log（重做日志） 实现持久化和原子性 在innoDB的存储引擎中，事务日志通过重做(redo)日志和innoDB存储引擎的日志缓冲(InnoDB Log Buffer)实现。事务开启时，事务中的操作，都会先写入存储引擎的日志缓冲中，在事务提交之前，这些缓冲的日志都需要提前刷新到磁盘上持久化，这就是DBA们口中常说的“日志先行”(Write-Ahead Logging)。当事务提交之后，在Buffer Pool中映射的数据文件才会慢慢刷新到磁盘。此时如果数据库崩溃或者宕机，那么当系统重启进行恢复时，就可以根据redo log中记录的日志，把数据库恢复到崩溃前的一个状态。未完成的事务，可以继续提交，也可以选择回滚，这基于恢复的策略而定。 在系统启动的时候，就已经为redo log分配了一块连续的存储空间，以顺序追加的方式记录Redo Log，通过顺序IO来改善性能。所有的事务共享redo log的存储空间，它们的Redo Log按语句的执行顺序，依次交替的记录在一起。 undo log（回滚日志） 实现一致性 undo log 主要为事务的回滚服务。在事务执行的过程中，除了记录redo log，还会记录一定量的undo log。undo log记录了数据在每个操作前的状态，如果事务执行过程中需要回滚，就可以根据undo log进行回滚操作。单个事务的回滚，只会回滚当前事务做的操作，并不会影响到其他的事务做的操作。 Undo记录的是已部分完成并且写入硬盘的未完成的事务，默认情况下回滚日志是记录下表空间中的（共享表空间或者独享表空间） 二种日志均可以视为一种恢复操作，redo_log是恢复提交事务修改的页操作，而undo_log是回滚行记录到特定版本。二者记录的内容也不同，redo_log是物理日志，记录页的物理修改操作，而undo_log是逻辑日志，根据每行记录进行记录。 又引出个问题：你知道MySQL 有多少种日志吗？ 错误日志：记录出错信息，也记录一些警告信息或者正确的信息。 查询日志：记录所有对数据库请求的信息，不论这些请求是否得到了正确的执行。 慢查询日志：设置一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询的日志文件中。 二进制日志：记录对数据库执行更改的所有操作。 中继日志：中继日志也是二进制日志，用来给slave 库恢复 事务日志：重做日志redo和回滚日志undo 分布式事务相关问题，可能还会问到 2PC、3PC，，， MySQL对分布式事务的支持分布式事务的实现方式有很多，既可以采用 InnoDB 提供的原生的事务支持，也可以采用消息队列来实现分布式事务的最终一致性。这里我们主要聊一下 InnoDB 对分布式事务的支持。 MySQL 从 5.0.3 InnoDB 存储引擎开始支持XA协议的分布式事务。一个分布式事务会涉及多个行动，这些行动本身是事务性的。所有行动都必须一起成功完成，或者一起被回滚。 在MySQL中，使用分布式事务涉及一个或多个资源管理器和一个事务管理器。 如图，MySQL 的分布式事务模型。模型中分三块：应用程序（AP）、资源管理器（RM）、事务管理器（TM）: 应用程序：定义了事务的边界，指定需要做哪些事务； 资源管理器：提供了访问事务的方法，通常一个数据库就是一个资源管理器； 事务管理器：协调参与了全局事务中的各个事务。 分布式事务采用两段式提交（two-phase commit）的方式： 第一阶段所有的事务节点开始准备，告诉事务管理器ready。 第二阶段事务管理器告诉每个节点是commit还是rollback。如果有一个节点失败，就需要全局的节点全部rollback，以此保障事务的原子性。 七、MySQL锁机制 数据库的乐观锁和悲观锁？ MySQL 中有哪几种锁，列举一下？ MySQL中InnoDB引擎的行锁是怎么实现的？ MySQL 间隙锁有没有了解，死锁有没有了解，写一段会造成死锁的 sql 语句，死锁发生了如何解决，MySQL 有没有提供什么机制去解决死锁 锁是计算机协调多个进程或线程并发访问某一资源的机制。 在数据库中，除传统的计算资源（如CPU、RAM、I/O等）的争用以外，数据也是一种供许多用户共享的资源。数据库锁定机制简单来说，就是数据库为了保证数据的一致性，而使各种共享资源在被并发访问变得有序所设计的一种规则。 打个比方，我们到淘宝上买一件商品，商品只有一件库存，这个时候如果还有另一个人买，那么如何解决是你买到还是另一个人买到的问题？这里肯定要用到事物，我们先从库存表中取出物品数量，然后插入订单，付款后插入付款表信息，然后更新商品数量。在这个过程中，使用锁可以对有限的资源进行保护，解决隔离和并发的矛盾。 锁的分类从对数据操作的类型分类： 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行，不会互相影响 写锁（排他锁）：当前写操作没有完成前，它会阻断其他写锁和读锁 从对数据操作的粒度分类： 为了尽可能提高数据库的并发度，每次锁定的数据范围越小越好，理论上每次只锁定当前操作的数据的方案会得到最大的并发度，但是管理锁是很耗资源的事情（涉及获取，检查，释放锁等动作），因此数据库系统需要在高并发响应和系统性能两方面进行平衡，这样就产生了“锁粒度（Lock granularity）”的概念。 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低（MyISAM 和 MEMORY 存储引擎采用的是表级锁）； 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高（InnoDB 存储引擎既支持行级锁也支持表级锁，但默认情况下是采用行级锁）； 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 适用：从锁的角度来说，表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如Web应用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统。 引擎 行锁 表锁 页锁 MyISAM √ BDB √ √ InnoDB √ √ Memory √ MyISAM 表锁MyISAM 的表锁有两种模式： 表共享读锁 （Table Read Lock）：不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求； 表独占写锁 （Table Write Lock）：会阻塞其他用户对同一表的读和写操作； MyISAM 表的读操作与写操作之间，以及写操作之间是串行的。当一个线程获得对一个表的写锁后， 只有持有锁的线程可以对表进行更新操作。 其他线程的读、 写操作都会等待，直到锁被释放为止。 默认情况下，写锁比读锁具有更高的优先级：当一个锁释放时，这个锁会优先给写锁队列中等候的获取锁请求，然后再给读锁队列中等候的获取锁请求。 InnoDB 行锁InnoDB 实现了以下两种类型的行锁： 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。 排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。 为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁： 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。 索引失效会导致行锁变表锁。比如 vchar 查询不写单引号的情况。 加锁机制乐观锁与悲观锁是两种并发控制的思想，可用于解决丢失更新问题 乐观锁会“乐观地”假定大概率不会发生并发更新冲突，访问、处理数据过程中不加锁，只在更新数据时再根据版本号或时间戳判断是否有冲突，有则处理，无则提交事务。用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式 悲观锁会“悲观地”假定大概率会发生并发更新冲突，访问、处理数据前就加排他锁，在整个数据处理过程中锁定数据，事务提交或回滚后才释放锁。另外与乐观锁相对应的，悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。 锁模式(InnoDB有三种行锁的算法) 记录锁(Record Locks)： 单个行记录上的锁。对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项； 1SELECT * FROM table WHERE id = 1 FOR UPDATE; 它会在 id=1 的记录上加上记录锁，以阻止其他事务插入，更新，删除 id=1 这一行 在通过 主键索引 与 唯一索引 对数据行进行 UPDATE 操作时，也会对该行数据加记录锁： 12-- id 列为主键列或唯一索引列UPDATE SET age = 50 WHERE id = 1; 间隙锁（Gap Locks）： 当我们使用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙”。 InnoDB 也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。 对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁），不包含索引项本身。其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。 间隙锁基于非唯一索引，它锁定一段范围内的索引记录。间隙锁基于下面将会提到的Next-Key Locking 算法，请务必牢记：使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。 1SELECT * FROM table WHERE id BETWEN 1 AND 10 FOR UPDATE; 即所有在（1，10）区间内的记录行都会被锁住，所有id 为 2、3、4、5、6、7、8、9 的数据行的插入会被阻塞，但是 1 和 10 两条记录行并不会被锁住。 GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况 临键锁(Next-key Locks)： 临键锁，是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。(临键锁的主要目的，也是为了避免幻读(Phantom Read)。如果把事务的隔离级别降级为RC，临键锁则也会失效。) Next-Key 可以理解为一种特殊的间隙锁，也可以理解为一种特殊的算法。通过临建锁可以解决幻读的问题。 每个数据行上的非唯一索引列上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据。需要强调的一点是，InnoDB 中行级锁是基于索引实现的，临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。 对于行的查询，都是采用该方法，主要目的是解决幻读的问题。 select for update有什么含义，会锁表还是锁行还是其他 for update 仅适用于InnoDB，且必须在事务块(BEGIN/COMMIT)中才能生效。在进行事务操作时，通过“for update”语句，MySQL会对查询结果集中每行数据都添加排他锁，其他线程对该记录的更新与删除操作都会阻塞。排他锁包含行锁、表锁。 InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！ 假设有个表单 products ，里面有id跟name二个栏位，id是主键。 明确指定主键，并且有此笔资料，row lock 12SELECT * FROM products WHERE id=&apos;3&apos; FOR UPDATE;SELECT * FROM products WHERE id=&apos;3&apos; and type=1 FOR UPDATE; 明确指定主键，若查无此笔资料，无lock 1SELECT * FROM products WHERE id=&apos;-1&apos; FOR UPDATE; 无主键，table lock 1SELECT * FROM products WHERE name=&apos;Mouse&apos; FOR UPDATE; 主键不明确，table lock 1SELECT * FROM products WHERE id&lt;&gt;&apos;3&apos; FOR UPDATE; 主键不明确，table lock 1SELECT * FROM products WHERE id LIKE &apos;3&apos; FOR UPDATE; 注1: FOR UPDATE仅适用于InnoDB，且必须在交易区块(BEGIN/COMMIT)中才能生效。 注2: 要测试锁定的状况，可以利用MySQL的Command Mode ，开二个视窗来做测试。 MySQL 遇到过死锁问题吗，你是如何解决的？ 死锁死锁产生： 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环 当事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时也可能会产生死锁 锁的行为和顺序和存储引擎相关。以同样的顺序执行语句，有些存储引擎会产生死锁有些不会——死锁有双重原因：真正的数据冲突；存储引擎的实现方式。 检测死锁：数据库系统实现了各种死锁检测和死锁超时的机制。InnoDB存储引擎能检测到死锁的循环依赖并立即返回一个错误。 死锁恢复：死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁，InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。 外部锁的死锁检测：发生死锁后，InnoDB 一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁， 这需要通过设置锁等待超时参数 innodb_lock_wait_timeout 来解决 死锁影响性能：死锁会影响性能而不是会产生严重错误，因为InnoDB会自动检测死锁状况并回滚其中一个受影响的事务。在高并发系统上，当许多线程等待同一个锁时，死锁检测可能导致速度变慢。 有时当发生死锁时，禁用死锁检测（使用innodb_deadlock_detect配置选项）可能会更有效，这时可以依赖innodb_lock_wait_timeout设置进行事务回滚。 MyISAM避免死锁： 在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，所以 MyISAM 表不会出现死锁。 InnoDB避免死锁： 为了在单个InnoDB表上执行多个并发写入操作时避免死锁，可以在事务开始时通过为预期要修改的每个元祖（行）使用SELECT ... FOR UPDATE语句来获取必要的锁，即使这些行的更改语句是在之后才执行的。 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁、更新时再申请排他锁，因为这时候当用户再申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁 如果事务需要修改或锁定多个表，则应在每个事务中以相同的顺序使用加锁语句。 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会 通过SELECT ... LOCK IN SHARE MODE获取行的读锁后，如果当前事务再需要对该记录进行更新操作，则很有可能造成死锁。 改变事务隔离级别 如果出现死锁，可以用 show engine innodb status;命令来确定最后一个死锁产生的原因。返回结果中包括死锁相关事务的详细信息，如引发死锁的 SQL 语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。 八、MySQL调优 日常工作中你是怎么优化SQL的？ SQL优化的一般步骤是什么，怎么看执行计划（explain），如何理解其中各个字段的含义？ 如何写sql能够有效的使用到复合索引？ 一条sql执行过长的时间，你如何优化，从哪些方面入手？ 什么是最左前缀原则？什么是最左匹配原则？ 影响mysql的性能因素 业务需求对MySQL的影响(合适合度) 存储定位对MySQL的影响 不适合放进MySQL的数据 二进制多媒体数据 流水队列数据 超大文本数据 需要放进缓存的数据 系统各种配置及规则数据 活跃用户的基本信息数据 活跃用户的个性化定制信息数据 准实时的统计信息数据 其他一些访问频繁但变更较少的数据 Schema设计对系统的性能影响 尽量减少对数据库访问的请求 尽量减少无用数据的查询请求 硬件环境对系统性能的影响 性能分析MySQL Query Optimizer MySQL 中有专门负责优化 SELECT 语句的优化器模块，主要功能：通过计算分析系统中收集到的统计信息，为客户端请求的 Query 提供他认为最优的执行计划（他认为最优的数据检索方式，但不见得是 DBA 认为是最优的，这部分最耗费时间） 当客户端向 MySQL 请求一条 Query，命令解析器模块完成请求分类，区别出是 SELECT 并转发给 MySQL Query Optimize r时，MySQL Query Optimizer 首先会对整条 Query 进行优化，处理掉一些常量表达式的预算，直接换算成常量值。并对 Query 中的查询条件进行简化和转换，如去掉一些无用或显而易见的条件、结构调整等。然后分析 Query 中的 Hint 信息（如果有），看显示 Hint 信息是否可以完全确定该 Query 的执行计划。如果没有 Hint 或 Hint 信息还不足以完全确定执行计划，则会读取所涉及对象的统计信息，根据 Query 进行写相应的计算分析，然后再得出最后的执行计划。 MySQL常见瓶颈 CPU：CPU在饱和的时候一般发生在数据装入内存或从磁盘上读取数据时候 IO：磁盘I/O瓶颈发生在装入数据远大于内存容量的时候 服务器硬件的性能瓶颈：top，free，iostat 和 vmstat来查看系统的性能状态 性能下降SQL慢 执行时间长 等待时间长 原因分析 查询语句写的烂 索引失效（单值、复合） 关联查询太多join（设计缺陷或不得已的需求） 服务器调优及各个参数设置（缓冲、线程数等） MySQL常见性能分析手段在优化MySQL时，通常需要对数据库进行分析，常见的分析手段有慢查询日志，EXPLAIN 分析查询，profiling分析以及show命令查询系统状态及系统变量，通过定位分析性能的瓶颈，才能更好的优化数据库系统的性能。 性能瓶颈定位我们可以通过 show 命令查看 MySQL 状态及变量，找到系统的瓶颈： 1234567891011Mysql&gt; show status ——显示状态信息（扩展show status like ‘XXX’）Mysql&gt; show variables ——显示系统变量（扩展show variables like ‘XXX’）Mysql&gt; show innodb status ——显示InnoDB存储引擎的状态Mysql&gt; show processlist ——查看当前SQL执行，包括执行状态、是否锁表等Shell&gt; mysqladmin variables -u username -p password——显示系统变量Shell&gt; mysqladmin extended-status -u username -p password——显示状态信息 Explain(执行计划)是什么：使用 Explain 关键字可以模拟优化器执行SQL查询语句，从而知道 MySQL 是如何处理你的 SQL 语句的。分析你的查询语句或是表结构的性能瓶颈 能干吗： 表的读取顺序 数据读取操作的操作类型 哪些索引可以使用 哪些索引被实际使用 表之间的引用 每张表有多少行被优化器查询 怎么玩： Explain + SQL语句 执行计划包含的信息（如果有分区表的话还会有partitions） 各字段解释 id（select 查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序） id相同，执行顺序从上往下 id全不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 id部分相同，执行顺序是先按照数字大的先执行，然后数字相同的按照从上往下的顺序执行 select_type（查询类型，用于区别普通查询、联合查询、子查询等复杂查询） SIMPLE ：简单的select查询，查询中不包含子查询或UNION PRIMARY：查询中若包含任何复杂的子部分，最外层查询被标记为PRIMARY SUBQUERY：在select或where列表中包含了子查询 DERIVED：在from列表中包含的子查询被标记为DERIVED，MySQL会递归执行这些子查询，把结果放在临时表里 UNION：若第二个select出现在UNION之后，则被标记为UNION，若UNION包含在from子句的子查询中，外层select将被标记为DERIVED UNION RESULT：从UNION表获取结果的select table（显示这一行的数据是关于哪张表的） type（显示查询使用了那种类型，从最好到最差依次排列 system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL ） system：表只有一行记录（等于系统表），是 const 类型的特例，平时不会出现 const：表示通过索引一次就找到了，const 用于比较 primary key 或 unique 索引，因为只要匹配一行数据，所以很快，如将主键置于 where 列表中，mysql 就能将该查询转换为一个常量 eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配，常见于主键或唯一索引扫描 ref：非唯一性索引扫描，范围匹配某个单独值得所有行。本质上也是一种索引访问，他返回所有匹配某个单独值的行，然而，它可能也会找到多个符合条件的行，多以他应该属于查找和扫描的混合体 range：只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引，一般就是在你的where语句中出现了between、&lt;、&gt;、in等的查询，这种范围扫描索引比全表扫描要好，因为它只需开始于索引的某一点，而结束于另一点，不用扫描全部索引 index：Full Index Scan，index于ALL区别为index类型只遍历索引树。通常比ALL快，因为索引文件通常比数据文件小。（也就是说虽然all和index都是读全表，但index是从索引中读取的，而all是从硬盘中读的） ALL：Full Table Scan，将遍历全表找到匹配的行 tip: 一般来说，得保证查询至少达到range级别，最好到达ref possible_keys（显示可能应用在这张表中的索引，一个或多个，查询涉及到的字段若存在索引，则该索引将被列出，但不一定被查询实际使用） key 实际使用的索引，如果为NULL，则没有使用索引 查询中若使用了覆盖索引，则该索引和查询的 select 字段重叠，仅出现在key列表中 key_len 表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。在不损失精确性的情况下，长度越短越好 key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的 ref （显示索引的哪一列被使用了，如果可能的话，是一个常数。哪些列或常量被用于查找索引列上的值） rows （根据表统计信息及索引选用情况，大致估算找到所需的记录所需要读取的行数） Extra（包含不适合在其他列中显示但十分重要的额外信息） using filesort: 说明mysql会对数据使用一个外部的索引排序，不是按照表内的索引顺序进行读取。mysql中无法利用索引完成的排序操作称为“文件排序”。常见于order by和group by语句中 Using temporary：使用了临时表保存中间结果，mysql在对查询结果排序时使用临时表。常见于排序order by和分组查询group by。 using index：表示相应的select操作中使用了覆盖索引，避免访问了表的数据行，效率不错，如果同时出现using where，表明索引被用来执行索引键值的查找；否则索引被用来读取数据而非执行查找操作 using where：使用了where过滤 using join buffer：使用了连接缓存 impossible where：where子句的值总是false，不能用来获取任何元祖 select tables optimized away：在没有group by子句的情况下，基于索引优化操作或对于MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化 distinct：优化distinct操作，在找到第一匹配的元祖后即停止找同样值的动作 case: 第一行（执行顺序4）：id列为1，表示是union里的第一个select，select_type列的primary表示该查询为外层查询，table列被标记为，表示查询结果来自一个衍生表，其中derived3中3代表该查询衍生自第三个select查询，即id为3的select。【select d1.name……】 第二行（执行顺序2）：id为3，是整个查询中第三个select的一部分。因查询包含在from中，所以为derived。【select id,name from t1 where other_column=’’】 第三行（执行顺序3）：select列表中的子查询select_type为subquery，为整个查询中的第二个select。【select id from t3】 第四行（执行顺序1）：select_type为union，说明第四个select是union里的第二个select，最先执行【select name,id from t2】 第五行（执行顺序5）：代表从union的临时表中读取行的阶段，table列的&lt;union1,4&gt;表示用第一个和第四个select的结果进行union操作。【两个结果union操作】 慢查询日志MySQL 的慢查询日志是 MySQL 提供的一种日志记录，它用来记录在 MySQL 中响应时间超过阈值的语句，具体指运行时间超过 long_query_time 值的 SQL，则会被记录到慢查询日志中。 long_query_time 的默认值为10，意思是运行10秒以上的语句 默认情况下，MySQL数据库没有开启慢查询日志，需要手动设置参数开启 查看开启状态 1SHOW VARIABLES LIKE &apos;%slow_query_log%&apos; 开启慢查询日志 临时配置： 123mysql&gt; set global slow_query_log=&apos;ON&apos;;mysql&gt; set global slow_query_log_file=&apos;/var/lib/mysql/hostname-slow.log&apos;;mysql&gt; set global long_query_time=2; ​ 也可set文件位置，系统会默认给一个缺省文件host_name-slow.log ​ 使用set操作开启慢查询日志只对当前数据库生效，如果MySQL重启则会失效。 永久配置 修改配置文件my.cnf或my.ini，在[mysqld]一行下面加入两个配置参数 1234[mysqld]slow_query_log = ONslow_query_log_file = /var/lib/mysql/hostname-slow.loglong_query_time = 3 注：log-slow-queries 参数为慢查询日志存放的位置，一般这个目录要有 MySQL 的运行帐号的可写权限，一般都将这个目录设置为 MySQL 的数据存放目录；long_query_time=2 中的 2 表示查询超过两秒才记录；在my.cnf或者 my.ini 中添加 log-queries-not-using-indexes 参数，表示记录下没有使用索引的查询。 可以用 select sleep(4) 验证是否成功开启。 在生产环境中，如果手工分析日志，查找、分析SQL，还是比较费劲的，所以MySQL提供了日志分析工具mysqldumpslow。 通过 mysqldumpslow –help 查看操作帮助信息 得到返回记录集最多的10个SQL mysqldumpslow -s r -t 10 /var/lib/mysql/hostname-slow.log 得到访问次数最多的10个SQL mysqldumpslow -s c -t 10 /var/lib/mysql/hostname-slow.log 得到按照时间排序的前10条里面含有左连接的查询语句 mysqldumpslow -s t -t 10 -g &quot;left join&quot; /var/lib/mysql/hostname-slow.log 也可以和管道配合使用 mysqldumpslow -s r -t 10 /var/lib/mysql/hostname-slow.log | more 也可使用 pt-query-digest 分析 RDS MySQL 慢查询日志 Show Profile 分析查询通过慢日志查询可以知道哪些 SQL 语句执行效率低下，通过 explain 我们可以得知 SQL 语句的具体执行情况，索引使用等，还可以结合Show Profile命令查看执行状态。 Show Profile 是 MySQL 提供可以用来分析当前会话中语句执行的资源消耗情况。可以用于SQL的调优的测量 默认情况下，参数处于关闭状态，并保存最近15次的运行结果 分析步骤 是否支持，看看当前的mysql版本是否支持 1mysql&gt;Show variables like &apos;profiling&apos;; --默认是关闭，使用前需要开启 开启功能，默认是关闭，使用前需要开启 1mysql&gt;set profiling=1; 运行SQL 查看结果 1mysql&gt; show profiles; +----------+------------+---------------------------------+ | Query_ID | Duration | Query | +----------+------------+---------------------------------+ | 1 | 0.00385450 | show variables like &quot;profiling&quot; | | 2 | 0.00170050 | show variables like &quot;profiling&quot; | | 3 | 0.00038025 | select * from t_base_user | +----------+------------+---------------------------------+ 诊断SQL，show profile cpu,block io for query id(上一步前面的问题SQL数字号码) 日常开发需要注意的结论 converting HEAP to MyISAM 查询结果太大，内存都不够用了往磁盘上搬了。 create tmp table 创建临时表，这个要注意 Copying to tmp table on disk 把内存临时表复制到磁盘 locked 查询中哪些情况不会使用索引？ 性能优化索引优化 全值匹配我最爱 最佳左前缀法则，比如建立了一个联合索引(a,b,c)，那么其实我们可利用的索引就有(a), (a,b), (a,b,c) 不在索引列上做任何操作（计算、函数、(自动or手动)类型转换），会导致索引失效而转向全表扫描 存储引擎不能使用索引中范围条件右边的列 尽量使用覆盖索引(只访问索引的查询(索引列和查询列一致))，减少select is null ,is not null 也无法使用索引 like “xxxx%” 是可以用到索引的，like “%xxxx” 则不行(like “%xxx%” 同理)。like以通配符开头(‘%abc…’)索引失效会变成全表扫描的操作， 字符串不加单引号索引失效 少用or，用它来连接时会索引失效 &lt;，&lt;=，=，&gt;，&gt;=，BETWEEN，IN 可用到索引，&lt;&gt;，not in ，!= 则不行，会导致全表扫描 一般性建议 对于单键索引，尽量选择针对当前query过滤性更好的索引 在选择组合索引的时候，当前Query中过滤性最好的字段在索引字段顺序中，位置越靠前越好。 在选择组合索引的时候，尽量选择可以能够包含当前query中的where字句中更多字段的索引 尽可能通过分析统计信息和调整query的写法来达到选择合适索引的目的 少用Hint强制索引 查询优化永远小标驱动大表（小的数据集驱动大的数据集） 12345slect * from A where id in (select id from B)`等价于#等价于select id from Bselect * from A where A.id=B.id复制代码 当 B 表的数据集必须小于 A 表的数据集时，用 in 优于 exists 12345select * from A where exists (select 1 from B where B.id=A.id)#等价于select * from Aselect * from B where B.id = A.id`复制代码 当 A 表的数据集小于B表的数据集时，用 exists优于用 in 注意：A表与B表的ID字段应建立索引。 order by关键字优化 order by子句，尽量使用 Index 方式排序，避免使用 FileSort 方式排序 MySQL 支持两种方式的排序，FileSort 和 Index，Index效率高，它指 MySQL 扫描索引本身完成排序，FileSort 效率较低； ORDER BY 满足两种情况，会使用Index方式排序；①ORDER BY语句使用索引最左前列 ②使用where子句与ORDER BY子句条件列组合满足索引最左前列 尽可能在索引列上完成排序操作，遵照索引建的最佳最前缀 如果不在索引列上，filesort 有两种算法，mysql就要启动双路排序和单路排序 双路排序：MySQL 4.1之前是使用双路排序,字面意思就是两次扫描磁盘，最终得到数据 单路排序：从磁盘读取查询需要的所有列，按照order by 列在 buffer对它们进行排序，然后扫描排序后的列表进行输出，效率高于双路排序 优化策略 增大sort_buffer_size参数的设置 增大max_lencth_for_sort_data参数的设置 GROUP BY关键字优化 group by实质是先排序后进行分组，遵照索引建的最佳左前缀 当无法使用索引列，增大 max_length_for_sort_data 参数的设置，增大sort_buffer_size参数的设置 where高于having，能写在where限定的条件就不要去having限定了 数据类型优化MySQL 支持的数据类型非常多，选择正确的数据类型对于获取高性能至关重要。不管存储哪种类型的数据，下面几个简单的原则都有助于做出更好的选择。 更小的通常更好：一般情况下，应该尽量使用可以正确存储数据的最小数据类型。 简单就好：简单的数据类型通常需要更少的CPU周期。例如，整数比字符操作代价更低，因为字符集和校对规则（排序规则）使字符比较比整型比较复杂。 尽量避免NULL：通常情况下最好指定列为NOT NULL 九、分区、分表、分库MySQL分区一般情况下我们创建的表对应一组存储文件，使用MyISAM存储引擎时是一个.MYI和.MYD文件，使用Innodb存储引擎时是一个.ibd和.frm（表结构）文件。 当数据量较大时（一般千万条记录级别以上），MySQL的性能就会开始下降，这时我们就需要将数据分散到多组存储文件，保证其单个文件的执行效率 能干嘛 逻辑数据分割 提高单一的写和读应用速度 提高分区范围读查询的速度 分割数据能够有多个不同的物理文件路径 高效的保存历史数据 怎么玩 首先查看当前数据库是否支持分区 MySQL5.6以及之前版本： 12SHOW VARIABLES LIKE &apos;%partition%&apos;;复制代码 MySQL5.6： 12show plugins;复制代码 分区类型及操作 RANGE分区：基于属于一个给定连续区间的列值，把多行分配给分区。mysql将会根据指定的拆分策略，,把数据放在不同的表文件上。相当于在文件上,被拆成了小块.但是,对外给客户的感觉还是一张表，透明的。 按照 range 来分，就是每个库一段连续的数据，这个一般是按比如时间范围来的，比如交易表啊，销售表啊等，可以根据年月来存放数据。可能会产生热点问题，大量的流量都打在最新的数据上了。 range 来分，好处在于说，扩容的时候很简单。 LIST分区：类似于按RANGE分区，每个分区必须明确定义。它们的主要区别在于，LIST分区中每个分区的定义和选择是基于某列的值从属于一个值列表集中的一个值，而RANGE分区是从属于一个连续区间值的集合。 HASH分区：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL 中有效的、产生非负整数值的任何表达式。 hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表 KEY分区：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数。必须有一列或多列包含整数值。 看上去分区表很帅气，为什么大部分互联网还是更多的选择自己分库分表来水平扩展咧？ 分区表，分区键设计不太灵活，如果不走分区键，很容易出现全表锁 一旦数据并发量上来，如果在分区表实施关联，就是一个灾难 自己分库分表，自己掌控业务场景与访问模式，可控。分区表，研发写了一个sql，都不确定mysql是怎么玩的，不太可控 随着业务的发展，业务越来越复杂，应用的模块越来越多，总的数据量很大，高并发读写操作均超过单个数据库服务器的处理能力怎么办？ 这个时候就出现了数据分片，数据分片指按照某个维度将存放在单一数据库中的数据分散地存放至多个数据库或表中。数据分片的有效手段就是对关系型数据库进行分库和分表。 区别于分区的是，分区一般都是放在单机里的，用的比较多的是时间范围分区，方便归档。只不过分库分表需要代码实现，分区则是mysql内部实现。分库分表和分区并不冲突，可以结合使用。 说说分库与分表的设计 MySQL分表分表有两种分割方式，一种垂直拆分，另一种水平拆分。 垂直拆分 垂直分表，通常是按照业务功能的使用频次，把主要的、热门的字段放在一起做为主要表。然后把不常用的，按照各自的业务属性进行聚集，拆分到不同的次要表中；主要表和次要表的关系一般都是一对一的。 水平拆分(数据分片) 单表的容量不超过500W，否则建议水平拆分。是把一个表复制成同样表结构的不同表，然后把数据按照一定的规则划分，分别存储到这些表中，从而保证单表的容量不会太大，提升性能；当然这些结构一样的表，可以放在一个或多个数据库中。 水平分割的几种方法： 使用MD5哈希，做法是对UID进行md5加密，然后取前几位（我们这里取前两位），然后就可以将不同的UID哈希到不同的用户表（user_xx）中了。 还可根据时间放入不同的表，比如：article_201601，article_201602。 按热度拆分，高点击率的词条生成各自的一张表，低热度的词条都放在一张大表里，待低热度的词条达到一定的贴数后，再把低热度的表单独拆分成一张表。 根据ID的值放入对应的表，第一个表user_0000，第二个100万的用户数据放在第二 个表user_0001中，随用户增加，直接添加用户表就行了。 MySQL分库 为什么要分库? 数据库集群环境后都是多台 slave，基本满足了读取操作; 但是写入或者说大数据、频繁的写入操作对master性能影响就比较大，这个时候，单库并不能解决大规模并发写入的问题，所以就会考虑分库。 分库是什么？ 一个库里表太多了，导致了海量数据，系统性能下降，把原本存储于一个库的表拆分存储到多个库上， 通常是将表按照功能模块、关系密切程度划分出来，部署到不同库上。 优点： 减少增量数据写入时的锁对查询的影响 由于单表数量下降，常见的查询操作由于减少了需要扫描的记录，使得单表单次查询所需的检索行数变少，减少了磁盘IO，时延变短 但是它无法解决单表数据量太大的问题 分库分表后的难题 分布式事务的问题，数据的完整性和一致性问题。 数据操作维度问题：用户、交易、订单各个不同的维度，用户查询维度、产品数据分析维度的不同对比分析角度。 跨库联合查询的问题，可能需要两次查询 跨节点的count、order by、group by以及聚合函数问题，可能需要分别在各个节点上得到结果后在应用程序端进行合并 额外的数据管理负担，如：访问数据表的导航定位 额外的数据运算压力，如：需要在多个节点执行，然后再合并计算程序编码开发难度提升，没有太好的框架解决，更多依赖业务看如何分，如何合，是个难题。 配主从，正经公司的话，也不会让 Javaer 去搞的，但还是要知道 十、主从复制复制的基本原理 slave 会从 master 读取 binlog 来进行数据同步 三个步骤 master将改变记录到二进制日志（binary log）。这些记录过程叫做二进制日志事件，binary log events； salve 将 master 的 binary log events 拷贝到它的中继日志（relay log）; slave 重做中继日志中的事件，将改变应用到自己的数据库中。MySQL 复制是异步且是串行化的。 复制的基本原则 每个 slave只有一个 master 每个 salve只能有一个唯一的服务器 ID 每个master可以有多个salve 复制的最大问题 延时 十一、其他问题说一说三个范式 第一范式（1NF）：数据库表中的字段都是单一属性的，不可再分。这个单一属性由基本类型构成，包括整型、实数、字符型、逻辑型、日期型等。 第二范式（2NF）：数据库表中不存在非关键字段对任一候选关键字段的部分函数依赖（部分函数依赖指的是存在组合关键字中的某些字段决定非关键字段的情况），也即所有非关键字段都完全依赖于任意一组候选关键字。 第三范式（3NF）：在第二范式的基础上，数据表中如果不存在非关键字段对任一候选关键字段的传递函数依赖则符合第三范式。所谓传递函数依赖，指的是如 果存在”A → B → C”的决定关系，则C传递函数依赖于A。因此，满足第三范式的数据库表应该不存在如下依赖关系： 关键字段 → 非关键字段 x → 非关键字段y 百万级别或以上的数据如何删除关于索引：由于索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，查询MySQL官方手册得知删除数据的速度和创建的索引数量是成正比的。 所以我们想要删除百万数据的时候可以先删除索引（此时大概耗时三分多钟） 然后删除其中无用数据（此过程需要不到两分钟） 删除完成后重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。 与之前的直接删除绝对是要快速很多，更别说万一删除中断,一切删除会回滚。那更是坑了。 参考与感谢：EnjoyMoving 程序员内点事 菜鸟笔记 特别声明：版权归原作者所有如有侵权请立即与我联系，我将及时处理","categories":[{"name":"收藏","slug":"收藏","permalink":"https://sangedon.cn/categories/收藏/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://sangedon.cn/tags/数据库/"},{"name":"mysql","slug":"mysql","permalink":"https://sangedon.cn/tags/mysql/"}]},{"title":"Java动态追踪技术探究","slug":"Java动态追踪技术探究","date":"2020-10-21T13:45:30.000Z","updated":"2020-10-22T13:27:27.377Z","comments":true,"path":"paper/Java动态追踪技术探究/","link":"","permalink":"https://sangedon.cn/paper/Java动态追踪技术探究/","excerpt":"","text":"作者：美团｜高扬 引子在遥远的希艾斯星球爪哇国塞沃城中，两名年轻的程序员正在为一件事情苦恼，程序出问题了，一时看不出问题出在哪里，于是有了以下对话： “Debug一下吧。” “线上机器，没开Debug端口。” “看日志，看看请求值和返回值分别是什么？” “那段代码没打印日志。” “改代码，加日志，重新发布一次。” “怀疑是线程池的问题，重启会破坏现场。” 长达几十秒的沉默之后：“据说，排查问题的最高境界，就是只通过Review代码来发现问题。” 比几十秒长几十倍的沉默之后：“我轮询了那段代码一十七遍之后，终于得出一个结论。” “结论是？” “我还没到达只通过Review代码就能发现问题的至高境界。” 从JSP说起对于大多数Java程序员来说，早期的时候，都会接触到一个叫做JSP（Java Server Pages）的技术。虽然这种技术，在前后端代码分离、前后端逻辑分离、前后端组织架构分离的今天来看，已经过时了，但是其中还是有一些有意思的东西，值得拿出来说一说。 当时刚刚处于Java入门时期的我们，大多数精力似乎都放在了JSP的页面展示效果上了： “这个表格显示的行数不对” “原来是for循环写的有问题，改一下，刷新页面再试一遍” “嗯，好了，表格显示没问题了，但是，登录人的姓名没取到啊，是不是Sesstion获取有问题？” “有可能，我再改一下，一会儿再刷新试试” …… 在一遍一遍修改代码刷新浏览器页面重试的时候，我们自己也许并没有注意到一件很酷的事情：我们修改完代码，居然只是简单地刷新一遍浏览器页面，修改就生效了，整个过程并没有重启JVM。按照我们的常识，Java程序一般都是在启动时加载类文件，如果都像JSP这样修改完代码，不用重启就生效的话，那文章开头的问题就可以解决了啊：Java文件中加一段日志打印的代码，不重启就生效，既不破坏现场，又可以定位问题。忍不住试一试：修改、编译、替换class文件。额，不行，新改的代码并没有生效。那为什么偏偏JSP可以呢？让我们先来看看JSP的运行原理。 当我们打开浏览器，请求访问一个JSP文件的时候，整个过程是这样的: JSP文件修改过后，之所以能及时生效，是因为Web容器（Tomcat）会检查请求的JSP文件是否被更改过。如果发生过更改，那么就将JSP文件重新解析翻译成一个新的Sevlet类，并加载到JVM中。之后的请求，都会由这个新的Servet来处理。这里有个问题，根据Java的类加载机制，在同一个ClassLoader中，类是不允许重复的。为了绕开这个限制，Web容器每次都会创建一个新的ClassLoader实例，来加载新编译的Servlet类。之后的请求都会由这个新的Servlet来处理，这样就实现了新旧JSP的切换。 HTTP服务是无状态的，所以JSP的场景基本上都是一次性消费，这种通过创建新的ClassLoader来“替换”class的做法行得通，但是对于其他应用，比如Spring框架，即便这样做了，对象多数是单例，对于内存中已经创建好的对象，我们无法通过这种创建新的ClassLoader实例的方法来修改对象行为。 我就是想不重启应用加个日志打印，就这么难吗？ Java对象行为既然JSP的办法行不通，那我们来看看还有没有其他的办法。仔细想想，我们会发现，文章开头的问题本质上是动态改变内存中已存在对象的行为的问题。所以，我们得先弄清楚JVM中和对象行为有关的地方在哪里，有没有更改的可能性。 我们都知道，对象使用两种东西来描述事物：行为和属性。举个例子： 123456789101112131415161718192021public class Person&#123; private int age; private String name; public void speak(String str) &#123; System.out.println(str); &#125; public Person(int age, String name) &#123; this.age = age; this.name = name; &#125;&#125; 上面Person类中age和name是属性，speak是行为。对象是类的事例，每个对象的属性都属于对象本身，但是每个对象的行为却是公共的。举个例子，比如我们现在基于Person类创建了两个对象，personA和personB： 1234567Person personA = new Person(43, \"lixunhuan\");personA.speak(\"我是李寻欢\");Person personB = new Person(23, \"afei\");personB.speak(\"我是阿飞\"); personA和personB有各自的姓名和年龄，但是有共同的行为：speak。想象一下，如果我们是Java语言的设计者，我们会怎么存储对象的行为和属性呢？ “很简单，属性跟着对象走，每个对象都存一份。行为是公共的东西，抽离出来，单独放到一个地方。” “咦？抽离出公共的部分，跟代码复用好像啊。” “大道至简，很多东西本来都是殊途同归。” 也就是说，第一步我们首先得找到存储对象行为的这个公共的地方。一番搜索之后，我们发现这样一段描述： Method area is created on virtual machine startup, shared among all Java virtual machine threads and it is logically part of heap area. It stores per-class structures such as the run-time constant pool, field and method data, and the code for methods and constructors. Java的对象行为（方法、函数）是存储在方法区的。 “方法区中的数据从哪来？” “方法区中的数据是类加载时从class文件中提取出来的。” “class文件从哪来？” “从Java或者其他符合JVM规范的源代码中编译而来。” “源代码从哪来？” “废话，当然是手写！” “倒着推，手写没问题，编译没问题，至于加载……有没有办法加载一个已经加载过的类呢？如果有的话，我们就能修改字节码中目标方法所在的区域，然后重新加载这个类，这样方法区中的对象行为（方法）就被改变了，而且不改变对象的属性，也不影响已经存在对象的状态，那么就可以搞定这个问题了。可是，这岂不是违背了JVM的类加载原理？毕竟我们不想改变ClassLoader。” “少年，可以去看看java.lang.instrument.Instrumentation。” java.lang.instrument.Instrumentation看完文档之后，我们发现这么两个接口：redefineClasses和retransformClasses。一个是重新定义class，一个是修改class。这两个大同小异，看reDefineClasses的说明： This method is used to replace the definition of a class without reference to the existing class file bytes, as one might do when recompiling from source for fix-and-continue debugging. Where the existing class file bytes are to be transformed (for example in bytecode instrumentation) retransformClasses should be used. 都是替换已经存在的class文件，redefineClasses是自己提供字节码文件替换掉已存在的class文件，retransformClasses是在已存在的字节码文件上修改后再替换之。 当然，运行时直接替换类很不安全。比如新的class文件引用了一个不存在的类，或者把某个类的一个field给删除了等等，这些情况都会引发异常。所以如文档中所言，instrument存在诸多的限制： The redefinition may change method bodies, the constant pool and attributes. The redefinition must not add, remove or rename fields or methods, change the signatures of methods, or change inheritance. These restrictions maybe be lifted in future versions. The class file bytes are not checked, verified and installed until after the transformations have been applied, if the resultant bytes are in error this method will throw an exception. 我们能做的基本上也就是简单修改方法内的一些行为，这对于我们开头的问题，打印一段日志来说，已经足够了。当然，我们除了通过reTransform来打印日志，还能做很多其他非常有用的事情，这个下文会进行介绍。 那怎么得到我们需要的class文件呢？一个最简单的方法，是把修改后的Java文件重新编译一遍得到class文件，然后调用redefineClasses替换。但是对于没有（或者拿不到，或者不方便修改）源码的文件我们应该怎么办呢？其实对于JVM来说，不管是Java也好，Scala也好，任何一种符合JVM规范的语言的源代码，都可以编译成class文件。JVM的操作对象是class文件，而不是源码。所以，从这种意义上来讲，我们可以说“JVM跟语言无关”。既然如此，不管有没有源码，其实我们只需要修改class文件就行了。 直接操作字节码Java是软件开发人员能读懂的语言，class字节码是JVM能读懂的语言，class字节码最终会被JVM解释成机器能读懂的语言。无论哪种语言，都是人创造的。所以，理论上（实际上也确实如此）人能读懂上述任何一种语言，既然能读懂，自然能修改。只要我们愿意，我们完全可以跳过Java编译器，直接写字节码文件，只不过这并不符合时代的发展罢了，毕竟高级语言设计之始就是为我们人类所服务，其开发效率也比机器语言高很多。 对于人类来说，字节码文件的可读性远远没有Java代码高。尽管如此，还是有一些杰出的程序员们创造出了可以用来直接编辑字节码的框架，提供接口可以让我们方便地操作字节码文件，进行注入修改类的方法，动态创造一个新的类等等操作。其中最著名的框架应该就是ASM了，cglib、Spring等框架中对于字节码的操作就建立在ASM之上。 我们都知道，Spring的AOP是基于动态代理实现的，Spring会在运行时动态创建代理类，代理类中引用被代理类，在被代理的方法执行前后进行一些神秘的操作。那么，Spring是怎么在运行时创建代理类的呢？动态代理的美妙之处，就在于我们不必手动为每个需要被代理的类写代理类代码，Spring在运行时会根据需要动态地创造出一个类，这里创造的过程并非通过字符串写Java文件，然后编译成class文件，然后加载。Spring会直接“创造”一个class文件，然后加载，创造class文件的工具，就是ASM了。 到这里，我们知道了用ASM框架直接操作class文件，在类中加一段打印日志的代码，然后调用retransformClasses就可以了。 BTrace截止到目前，我们都是停留在理论描述的层面。那么如何进行实现呢？先来看几个问题： 在我们的工程中，谁来做这个寻找字节码，修改字节码，然后reTransform的动作呢？我们并非先知，不可能知道未来有没有可能遇到文章开头的这种问题。考虑到性价比，我们也不可能在每个工程中都开发一段专门做这些修改字节码、重新加载字节码的代码。 如果JVM不在本地，在远程呢？ 如果连ASM都不会用呢？能不能更通用一些，更“傻瓜”一些。 幸运的是，因为有BTrace的存在，我们不必自己写一套这样的工具了。什么是BTrace呢？BTrace已经开源，项目描述极其简短： A safe, dynamic tracing tool for the Java platform. BTrace是基于Java语言的一个安全的、可提供动态追踪服务的工具。BTrace基于ASM、Java Attach Api、Instruments开发，为用户提供了很多注解。依靠这些注解，我们可以编写BTrace脚本（简单的Java代码）达到我们想要的效果，而不必深陷于ASM对字节码的操作中不可自拔。 看BTrace官方提供的一个简单例子：拦截所有java.io包中所有类中以read开头的方法，打印类名、方法名和参数名。当程序IO负载比较高的时候，就可以从输出的信息中看到是哪些类所引起，是不是很方便？ 1234567891011121314151617181920212223242526package com.sun.btrace.samples;import com.sun.btrace.annotations.*;import com.sun.btrace.AnyType;import static com.sun.btrace.BTraceUtils.*;/** * This sample demonstrates regular expression * probe matching and getting input arguments * as an array - so that any overload variant * can be traced in \"one place\". This example * traces any \"readXX\" method on any class in * java.io package. Probed class, method and arg * array is printed in the action. */@BTrace public class ArgArray &#123; @OnMethod( clazz=\"/java\\\\.io\\\\..*/\", method=\"/read.*/\" ) public static void anyRead(@ProbeClassName String pcn, @ProbeMethodName String pmn, AnyType[] args) &#123; println(pcn); println(pmn); printArray(args); &#125;&#125; 再来看另一个例子：每隔2秒打印截止到当前创建过的线程数。 1234567891011121314151617181920212223242526272829303132333435363738package com.sun.btrace.samples;import com.sun.btrace.annotations.*;import static com.sun.btrace.BTraceUtils.*;import com.sun.btrace.annotations.Export;/** * This sample creates a jvmstat counter and * increments it everytime Thread.start() is * called. This thread count may be accessed * from outside the process. The @Export annotated * fields are mapped to jvmstat counters. The counter * name is \"btrace.\" + &lt;className&gt; + \".\" + &lt;fieldName&gt; */ @BTrace public class ThreadCounter &#123; // create a jvmstat counter using @Export @Export private static long count; @OnMethod( clazz=\"java.lang.Thread\", method=\"start\" ) public static void onnewThread(@Self Thread t) &#123; // updating counter is easy. Just assign to // the static field! count++; &#125; @OnTimer(2000) public static void ontimer() &#123; // we can access counter as \"count\" as well // as from jvmstat counter directly. println(count); // or equivalently ... println(Counters.perfLong(\"btrace.com.sun.btrace.samples.ThreadCounter.count\")); &#125;&#125; 看了上面的用法是不是有所启发？忍不住冒出来许多想法。比如查看HashMap什么时候会触发rehash，以及此时容器中有多少元素等等。 有了BTrace，文章开头的问题可以得到完美的解决。至于BTrace具体有哪些功能，脚本怎么写，这些Git上BTrace工程中有大量的说明和举例，网上介绍BTrace用法的文章更是恒河沙数，这里就不再赘述了。 我们明白了原理，又有好用的工具支持，剩下的就是发挥我们的创造力了，只需在合适的场景下合理地进行使用即可。 既然BTrace能解决上面我们提到的所有问题，那么BTrace的架构是怎样的呢？ BTrace主要有下面几个模块： BTrace脚本：利用BTrace定义的注解，我们可以很方便地根据需要进行脚本的开发。 Compiler：将BTrace脚本编译成BTrace class文件。 Client：将class文件发送到Agent。 Agent：基于Java的Attach Api，Agent可以动态附着到一个运行的JVM上，然后开启一个BTrace Server，接收client发过来的BTrace脚本；解析脚本，然后根据脚本中的规则找到要修改的类；修改字节码后，调用Java Instrument的reTransform接口，完成对对象行为的修改并使之生效。 整个BTrace的架构大致如下： BTrace最终借Instruments实现class的替换。如上文所说，出于安全考虑，Instruments在使用上存在诸多的限制，BTrace也不例外。BTrace对JVM来说是“只读的”，因此BTrace脚本的限制如下： 不允许创建对象 不允许创建数组 不允许抛异常 不允许catch异常 不允许随意调用其他对象或者类的方法，只允许调用com.sun.btrace.BTraceUtils中提供的静态方法（一些数据处理和信息输出工具） 不允许改变类的属性 不允许有成员变量和方法，只允许存在static public void方法 不允许有内部类、嵌套类 不允许有同步方法和同步块 不允许有循环 不允许随意继承其他类（当然，java.lang.Object除外） 不允许实现接口 不允许使用assert 不允许使用Class对象 如此多的限制，其实可以理解。BTrace要做的是，虽然修改了字节码，但是除了输出需要的信息外，对整个程序的正常运行并没有影响。 ArthasBTrace脚本在使用上有一定的学习成本，如果能把一些常用的功能封装起来，对外直接提供简单的命令即可操作的话，那就再好不过了。阿里的工程师们早已想到这一点，就在去年（2018年9月份），阿里巴巴开源了自己的Java诊断工具——Arthas。Arthas提供简单的命令行操作，功能强大。究其背后的技术原理，和本文中提到的大致无二。Arthas的文档很全面，想详细了解的话可以戳这里。 本文旨在说明Java动态追踪技术的来龙去脉，掌握技术背后的原理之后，只要愿意，各位读者也可以开发出自己的“冰封王座”出来。 尾声：三生万物现在，让我们试着站在更高的地方“俯瞰”这些问题。 Java的Instruments给运行时的动态追踪留下了希望，Attach API则给运行时动态追踪提供了“出入口”，ASM则大大方便了“人类”操作Java字节码的操作。 基于Instruments和Attach API前辈们创造出了诸如JProfiler、Jvisualvm、BTrace、Arthas这样的工具。以ASM为基础发展出了cglib、动态代理，继而是应用广泛的Spring AOP。 Java是静态语言，运行时不允许改变数据结构。然而，Java 5引入Instruments，Java 6引入Attach API之后，事情开始变得不一样了。虽然存在诸多限制，然而，在前辈们的努力下，仅仅是利用预留的近似于“只读”的这一点点狭小的空间，仍然创造出了各种大放异彩的技术，极大地提高了软件开发人员定位问题的效率。 计算机应该是人类有史以来最伟大的发明之一，从电磁感应磁生电，到高低电压模拟0和1的比特，再到二进制表示出几种基本类型，再到基本类型表示出无穷的对象，最后无穷的对象组合交互模拟现实生活乃至整个宇宙。 两千五百年前，《道德经》有言：“道生一，一生二，二生三，三生万物。” 两千五百年后，计算机的发展过程也大抵如此吧。 作者简介 高扬，2017年加入美团打车，负责美团打车结算系统的开发。 特别声明：版权归原作者所有如有侵权请立即与我联系，我将及时处理","categories":[{"name":"收藏","slug":"收藏","permalink":"https://sangedon.cn/categories/收藏/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://sangedon.cn/tags/Java/"},{"name":"动态追踪","slug":"动态追踪","permalink":"https://sangedon.cn/tags/动态追踪/"}]},{"title":"Mac下K8S环境搭建","slug":"Mac下K8S环境搭建","date":"2020-06-23T01:50:12.000Z","updated":"2020-10-21T14:15:11.105Z","comments":true,"path":"paper/Mac下K8S环境搭建/","link":"","permalink":"https://sangedon.cn/paper/Mac下K8S环境搭建/","excerpt":"","text":"搭建K8S环境参考文档：https://github.com/AliyunContainerService/k8s-for-docker-desktop docker 已安装，版本为 下载和 Kubernetes 版本匹配的k8s相关依赖镜像资源，配置好docker 的阿里云或者中科大的镜像加速 12# 下载命令git clone git@github.com:AliyunContainerService/k8s-for-docker-desktop.git -b v1.16.5 进入到下载的 k8s-for-docker-desktop 目录，执行如下命令 1./load_images.sh 勾选如下，重启即可 部署 Kubernetes dashboard（执行了第二条） 123kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc5/aio/deploy/recommended.yaml# 或kubectl create -f kubernetes-dashboard.yaml 检查 kubernetes-dashboard 应用状态 1kubectl get pod -n kubernetes-dashboard 开启 API Server 访问代理 1kubectl proxy 进入k8s仪表盘 链接：http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/#/login 配置控制台访问令牌 1234# 获取登陆 tokenTOKEN=$(kubectl -n kube-system describe secret default| awk '$1==\"token:\"&#123;print $2&#125;')kubectl config set-credentials docker-for-desktop --token=\"$&#123;TOKEN&#125;\"echo $TOKEN token 12User \"docker-for-desktop\" set.eyJhbGciOiJSUzI1NiIsImtpZCI6Ilp3bUthZkNlZzh3bWlsNDJoTkMxVS1nbm1RSU9TM1VPbXhDcURleG9WRnMifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZWZhdWx0LXRva2VuLWtmeDI3Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImRlZmF1bHQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIzMGM4MWU0OS1lY2QxLTQ1NjktOGY1Mi02OWZiNTMyOWNmYTgiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06ZGVmYXVsdCJ9.uasjTbEU1YEnsYJZ48SK6RBZ9f-SNw9UWimAPe4VQ-2YBExruye04FFREPKXIQw6TJCQ83Vh35kNNXQgYVjEhPMFbgG1oASJZ1fskEul8lBVD2jh41Ul7xrIs4DhADAGpov8nHib7OHN7pkEh8h3UicRdOlYD6pYw2hFvxmHy_ZZwZ8WFXlOeKxh-VT9PYx_LMsNHcZzySO7sQMq7N3jQN7eI8ZFIhoXkA0PaSIb4L0FPYqY0OpwKth0KB6E0181CWUdJVlcICpATL8KPR8HobbGn6uTF5r6gLSX58af1bxGeK4JvKf2sypMcoOdr1s-AYJ8ur7-3E98XWoqsW7UZQ 安装 ingress失败解决方案 12345678# 报错如下The connection to the server raw.githubusercontent.com was refused - did you specify the right host or port?# 解决如下sudo vi /etc/hosts# 添加如下配置即可解决151.101.76.133 raw.githubusercontent.com 安装kubesphere-minimal，参考：https://kubesphere.com.cn/docs/zh-CN/installation/prerequisites/ 1kubectl apply -f https://raw.githubusercontent.com/kubesphere/ks-installer/master/kubesphere-minimal.yaml 安装helm 下载：https://github.com/helm/helm/releases 版本：2.16.2 解压下载的文件后将可执行文件helm添加到path 1234567mv helm /usr/local/bin/# 验证安装helm version# 输出Client: &amp;version.Version&#123;SemVer:\"v2.16.2\", GitCommit:\"bbdfe5e7803a12bbdf97e94cd847859890cf4050\", GitTreeState:\"clean\"&#125; 初始化 helm 并安装 Tiller 1helm init --upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.16.2 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts","categories":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://sangedon.cn/categories/环境搭建/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://sangedon.cn/tags/docker/"},{"name":"Mac","slug":"Mac","permalink":"https://sangedon.cn/tags/Mac/"}]},{"title":"Mac下安装virturebox及vagrant虚拟机环境","slug":"Mac下安装virturebox及vagrant虚拟机环境","date":"2020-06-22T06:32:15.000Z","updated":"2020-10-21T14:15:18.641Z","comments":true,"path":"paper/Mac下安装virturebox及vagrant虚拟机环境/","link":"","permalink":"https://sangedon.cn/paper/Mac下安装virturebox及vagrant虚拟机环境/","excerpt":"","text":"安装virturebox下载：https://www.virtualbox.org/wiki/Downloads 版本：6.1.12 安装步骤：双击下一步即可 安装vagrant下载：https://www.vagrantup.com/downloads.html 版本：2.2.9 安装步骤：双击下一步即可 虚拟机Box下载地址 官方虚拟机box下载地址：https://app.vagrantup.com/boxes/search 仓库虚拟机box下载地址：http://www.vagrantbox.es/ 配置vagrant查看vagrant安装版本 1234# 输入vagrant -v# 输出Vagrant 2.2.9 检查已有的虚拟机列表vagrant box list，提示还没有任何虚拟机 12dongliangqiong@dongliaongdeMBP sangedon % vagrant box listThere are no installed boxes! Use `vagrant box add` to add some. 将官网box下载下来的 CentOS-7-x86_64-Vagrant-1902_01.VirtualBox.box放入 /Users/dongliangqiong/Documents/sangedon/devtools/software/vagrant目录，后执行如下操作 1vagrant box add centos7 /Users/dongliangqiong/Documents/sangedon/devtools/software/vagrant/CentOS-7-x86_64-Vagrant-1902_01.VirtualBox.box 执行vagrant init centos7，即可在当前目录生成此虚拟机的配置文件Vagrantfile 12345dongliangqiong@dongliaongdeMBP sangedon % vagrant init centos/7A `Vagrantfile` has been placed in this directory. You are nowready to `vagrant up` your first virtual environment! Please readthe comments in the Vagrantfile as well as documentation on`vagrantup.com` for more information on using Vagrant. 执行命令vagrant up，启动虚拟机（参考：http://www.voidcn.com/article/p-zmehqqii-bdx.html） 链接虚拟机 1vagrant ssh 设置root用户登陆 123456789101112# vagrant登陆进去之后跳转root账户sudo -s# 设置root账户账号passwd# 修改 /etc/ssh/sshd_config 文件，下面两项改为yesPermitRootLogin yesPasswordAuthentication yes# 重启服务service sshd restart 虚拟机创建成功，可通过 ssh root@ip 命令连接","categories":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://sangedon.cn/categories/环境搭建/"}],"tags":[{"name":"Mac","slug":"Mac","permalink":"https://sangedon.cn/tags/Mac/"}]},{"title":"Mac 电脑基础开发环境搭建","slug":"Mac-电脑基础开发环境搭建","date":"2020-06-12T05:19:17.000Z","updated":"2020-11-14T09:19:59.392Z","comments":true,"path":"paper/Mac-电脑基础开发环境搭建/","link":"","permalink":"https://sangedon.cn/paper/Mac-电脑基础开发环境搭建/","excerpt":"","text":"安装git官网下载： https://www.git-scm.com/download/ 版本：2.27.0 安装：下载后双击 -&gt; 下一步即可 配置 git 账号 12git config --global user.name \"sangedon\"git config --global user.email \"sange.dong@outlook.com\" 配置ssh1 、检查.ssh文件夹是否存在 1ls -al ~/.ssh 2、如果不存在新建.ssh文件平 1mkdir ~/.ssh 3、生成KEY在命令行中输入，sange.dong@outlook.com 12cd ~/.sshssh-keygen -t rsa -C \"sange.dong@outlook.com\" 系统提示输入文件保存位置等信息，连续按三次回车即可，生成的SSH key文件的保存路径会在终端中给出：id_rsa id_rsa.pub 4、查看公钥 1cat id_rsa.pub 安装 JDK1.8下载Mac版jdk网址：https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html oracle下载登陆账号：2696671285@qq.com / Oracle123 下载的版本：jdk-8u261-macosx-x64.dmg（1.8.0_261-b12） 安装： 双击一路向下即可 安装目录：/Library/Java/JavaVirtualMachines 安装 Maven官网下载：https://maven.apache.org/download.cgi 版本：3.6.3 解压（安装）目录：/Users/dongliangqiong/Documents/sangedon/devtools/software 添加环境变量 123456789# 创建.bash_profile文件vim ~/.bash_profile# 导出变量export MAVEN_HOME=/Users/dongliangqiong/Documents/sangedon/devtools/software/apache-maven-3.6.3export PATH=$PATH:$MAVEN_HOME/bin# 使生效source ~/.bash_profile 修改本地仓库路径： 修改文件：/Users/dongliangqiong/Documents/sangedon/devtools/software/apache-maven-3.6.3/conf/settings.xml 修改内容： 1&lt;localRepository&gt;/Users/dongliangqiong/Documents/sangedon/devtools/software/maven-repo&lt;/localRepository&gt; 安装Node相关 安装NodeJS 官网下载：https://nodejs.org/en/download/ 版本： Latest LTS Version: 12.18.3 (includes npm 6.14.6) 下载文件：node-v12.18.3.pkg 安装步骤：双击 -&gt; 下一步 即可 成功截图： 添加 淘宝npm镜像 1npm config set registry https://registry.npm.taobao.org 安装cnpm 代替 npm使用 1npm install -g cnpm --registry=https://registry.npm.taobao.org 安装hexo 1sudo npm install -g hexo 安装 yarn 1curl -o- -L https://yarnpkg.com/install.sh | bash","categories":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://sangedon.cn/categories/环境搭建/"}],"tags":[{"name":"Mac","slug":"Mac","permalink":"https://sangedon.cn/tags/Mac/"}]},{"title":"Java实现SSL双向认证","slug":"Java实现SSL双向认证","date":"2020-04-13T10:51:07.000Z","updated":"2020-10-21T14:16:04.859Z","comments":true,"path":"paper/Java实现SSL双向认证/","link":"","permalink":"https://sangedon.cn/paper/Java实现SSL双向认证/","excerpt":"","text":"通常客户端连接服务器时会需要校验服务器是否真实、正确，如浏览器输入 https://baidu.com，这种单向确认服务器是否可靠的认证方式为单向认证，实际场景中，我们还经常会需要同时验证服务器和客户端连接的双方是否均为安全、可靠，即服务端为每个用户颁发一个唯一的、不公开的数字证书，客户端通过数字证书来访问服务器，此时，客户端和服务器的交互就是在通信协议上附加SSL协议，确保了 1. 服务器和客户端均为安全可靠，互相认可，2. 通信内容是加密的，网络嗅探工具无法获取明文数据，这种认证方式即为双向认证 下面将通过JSSE（Java Security Socket Extension）来模拟Server 和 Client的双向认证 注：JSSE是Sun为了解决在Internet上的安全通讯而推出的解决方案。它实现了SSL和TSL（传输层安全）协议。在JSSE中包含了数据加密，服务器验证，消息完整性和客户端验证等技术。通过使用JSSE，开发人员可以在客户端和服务器之间通过TCP/IP协议安全地传输数据。 证书准备为了实现双向认证，Server 和 Client 端均需要如下两个信息文件（具体如下所列），在此使用Java自带的keytool命令生成证书文件 KeyStore：服务器端（客户端）的私钥 Trust KeyStore：保存服务器端（客户端）信任的授权证书 1. 生成服务器端私钥并导入到服务端KeyStore文件中，命令过程中需要填写一些内容，根据需求设置即可，如下图。 12345678910keytool -genkey -alias serverkey -keystore kserver.keystore# 需设置内容# keystore密码：123456# 名字和姓氏：sangedon# 组织单位名称：none# 组织名称：none# 城市或区域名称：BJ# 州或省份名称：BJ# 国家代码：CN 注：serverkey私钥的密码，不填写和keystore的密码保持一致。这里千万注意，直接回车就行，不用修改密码。否则在后面的程序中无法直接应用这个私钥，会报错。 生成的kserver.keystore是提供给服务端使用，其中保存了服务端的私钥 2. 根据私钥，导出服务端证书 1keytool -export -alias serverkey -keystore kserver.keystore -file server.crt server.crt就是服务端的证书 3. 将服务端证书，导入客户端Trust keyStore中 1keytool -import -alias serverkey -file server.crt -keystore tclient.keystore tclient.keystore为客户端保存的受信任的证书 使用上述同样的方法，生成客户端私钥，客户端证书，并导入到服务端受信任证书列表，命令如下： 1234&gt; keytool -genkey -alias clientkey -keystore kclient.keystore&gt; keytool -export -alias clientkey -keystore kclient.keystore -file client.crt&gt; keytool -import -alias clientkey -file client.crt -keystore tserver.keystore&gt; 生成如下证书文件 代码验证 客户端代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import java.io.BufferedInputStream;import java.io.BufferedOutputStream;import java.io.FileInputStream;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.nio.charset.StandardCharsets;import java.security.KeyStore;import javax.net.ssl.KeyManagerFactory;import javax.net.ssl.SSLContext;import javax.net.ssl.SSLSocket;import javax.net.ssl.TrustManagerFactory;/** * SSL 连接客户端 */public class Client &#123; private static final String HOST = \"127.0.0.1\"; private static final int PORT = 8888; private static final String CLIENT_KEY_STORE_PASSWORD = \"123456\"; private static final String CLIENT_TRUST_KEY_STORE_PASSWORD = \"123456\"; private static final String KS_FILE = \"client/kclient.keystore\"; private static final String TKS_FILE = \"client/tclient.keystore\"; private SSLSocket sslSocket; public static void main(String[] args) &#123; Client client = new Client(); client.init(); client.process(); &#125; /** * 建立连接处理 */ public void process() &#123; if (sslSocket == null) &#123; System.out.println(\"SSL 连接尚未建立\"); return; &#125; try &#123; InputStream is = sslSocket.getInputStream(); OutputStream os = sslSocket.getOutputStream(); BufferedInputStream bi = new BufferedInputStream(is); BufferedOutputStream bo = new BufferedOutputStream(os); bo.write(\"Client message\".getBytes(StandardCharsets.UTF_8)); bo.flush(); byte[] bytes = new byte[1024]; bi.read(bytes); System.out.println(new String(bytes, StandardCharsets.UTF_8)); sslSocket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; /** * 创建SSL对话上下文，导入客户端秘钥keystore，导入客户端信任的keystore（服务端证书），初始化SSLSocket连接 */ public void init() &#123; try &#123; SSLContext sslContext = SSLContext.getInstance(\"SSL\"); KeyManagerFactory keyManagerFactory = KeyManagerFactory.getInstance(\"SunX509\"); TrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(\"SunX509\"); KeyStore ks = KeyStore.getInstance(\"JKS\"); KeyStore tks = KeyStore.getInstance(\"JKS\"); ks.load(new FileInputStream(KS_FILE), CLIENT_KEY_STORE_PASSWORD.toCharArray()); tks.load(new FileInputStream(TKS_FILE), CLIENT_TRUST_KEY_STORE_PASSWORD.toCharArray()); keyManagerFactory.init(ks, CLIENT_KEY_STORE_PASSWORD.toCharArray()); trustManagerFactory.init(tks); sslContext.init(keyManagerFactory.getKeyManagers(), trustManagerFactory.getTrustManagers(), null); sslSocket = (SSLSocket) sslContext.getSocketFactory().createSocket(HOST, PORT); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 服务端代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import java.io.BufferedInputStream;import java.io.BufferedOutputStream;import java.io.FileInputStream;import java.io.InputStream;import java.io.OutputStream;import java.net.Socket;import java.nio.charset.StandardCharsets;import java.security.KeyStore;import javax.net.ssl.KeyManagerFactory;import javax.net.ssl.SSLContext;import javax.net.ssl.SSLServerSocket;import javax.net.ssl.TrustManagerFactory;/** * SSL 连接服务端 */public class Server &#123; private static final int PORT = 8888; private static final String SERVER_KEY_STORE_PASSWORD = \"123456\"; private static final String SERVER_TRUST_KEY_STORE_PASSWORD = \"123456\"; private static final String KS_FILE = \"server/kserver.keystore\"; private static final String TKS_FILE = \"server/tserver.keystore\"; private SSLServerSocket sslServerSocket; public static void main(String[] args) &#123; Server server = new Server(); server.init(); server.start(); &#125; /** * 等待客户端连接，进行通信 */ public void start() &#123; if (sslServerSocket == null) &#123; System.out.println(\"SSL 连接尚未建立\"); return; &#125; try &#123; Socket socket = sslServerSocket.accept(); InputStream is = socket.getInputStream(); OutputStream os = socket.getOutputStream(); BufferedInputStream bis = new BufferedInputStream(is); BufferedOutputStream bos = new BufferedOutputStream(os); byte[] bytes = new byte[1024]; bis.read(bytes); System.out.println(new String(bytes, StandardCharsets.UTF_8)); bos.write(\"Server accept\".getBytes(StandardCharsets.UTF_8)); bos.flush(); socket.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 创建SSL对话上下文，导入服务端秘钥keystore，导入服务端信任的keystore（客户端证书），初始化SSLServerSocket连接 */ public void init() &#123; try &#123; SSLContext sslContext = SSLContext.getInstance(\"SSL\"); KeyManagerFactory keyManagerFactory = KeyManagerFactory.getInstance(\"SunX509\"); TrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(\"SunX509\"); KeyStore ks = KeyStore.getInstance(\"JKS\"); KeyStore tks = KeyStore.getInstance(\"JKS\"); ks.load(new FileInputStream(KS_FILE), SERVER_KEY_STORE_PASSWORD.toCharArray()); tks.load(new FileInputStream(TKS_FILE), SERVER_TRUST_KEY_STORE_PASSWORD.toCharArray()); keyManagerFactory.init(ks, SERVER_KEY_STORE_PASSWORD.toCharArray()); trustManagerFactory.init(tks); sslContext.init(keyManagerFactory.getKeyManagers(), trustManagerFactory.getTrustManagers(), null); sslServerSocket = (SSLServerSocket) sslContext.getServerSocketFactory().createServerSocket(PORT); sslServerSocket.setNeedClientAuth(true); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 分别启动服务端和客户端即可验证","categories":[{"name":"Java","slug":"Java","permalink":"https://sangedon.cn/categories/Java/"}],"tags":[{"name":"加密技术","slug":"加密技术","permalink":"https://sangedon.cn/tags/加密技术/"}]},{"title":"Docker中安装Redis","slug":"Docker中安装Redis","date":"2019-09-20T07:51:27.000Z","updated":"2020-10-21T14:16:14.366Z","comments":true,"path":"paper/Docker中安装Redis/","link":"","permalink":"https://sangedon.cn/paper/Docker中安装Redis/","excerpt":"","text":"单机安装 下载 1docker pull redis 安装运行 1docker run --name redis -p 6379:6379 -v /opt/docker/redis/data:/data -v /opt/docker/redis/conf/redis.conf:/etc/redis/redis.conf -d redis redis-server /etc/redis/redis.conf 设置配置文件 12# 在/opt/docker/redis/conf/目录下生成配置文件即可，后续可补充配置，重启即可touch redis.conf","categories":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://sangedon.cn/categories/环境搭建/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://sangedon.cn/tags/docker/"}]},{"title":"Docker中安装MySQL","slug":"Docker中安装MySQL","date":"2019-09-20T07:05:52.000Z","updated":"2020-10-21T14:16:19.225Z","comments":true,"path":"paper/Docker中安装MySQL/","link":"","permalink":"https://sangedon.cn/paper/Docker中安装MySQL/","excerpt":"","text":"单实例安装 下载镜像 1docker pull mysql:5.7 安装 1docker run -p 3306:3306 --name mysql -v /opt/docker/mysql/log:/var/log/mysql -v /opt/docker/mysql/data:/var/lib/mysql -v /opt/docker/mysql/conf:/etc/mysql -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7 参数说明： -p 3306:3306 将容器的3306端口映射到主机的3306端口 -v 同步主机目录和容器目录 -e 初始化mysql的root用户密码 配置文件设置 1234567891011121314151617# 在/opt/docker/mysql/conf下执行vi my.cnf# 文件中将下列配置拷贝进去即可[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]init_connect='SET collation_connection=utf8_unicode_ci'init_connect='SET NAMES utf8'character-set-server=utf8collation-server=utf8_unicode_ciskip-character-set-client-handshakeskip-name-resolve 重启 1docker restart mysql MYSQL 服务启动成功！","categories":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://sangedon.cn/categories/环境搭建/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://sangedon.cn/tags/docker/"}]},{"title":"CentOS 7上Nginx的安装及基本配置","slug":"CentOS 7上nginx安装及相关配置","date":"2019-06-23T01:50:12.000Z","updated":"2020-11-16T05:28:16.049Z","comments":true,"path":"paper/CentOS 7上nginx安装及相关配置/","link":"","permalink":"https://sangedon.cn/paper/CentOS 7上nginx安装及相关配置/","excerpt":"","text":"Nginx (engine x) 是一个高性能的HTTP和反向代理服务，也是一个IMAP/POP3/SMTP服务。由俄罗斯人伊戈尔·赛索耶夫为Rambler.ru站点用C语言开发的，第一个公开版本0.1.0发布于2004年10月4日，2011年成立同名公司，以提供支持。其源代码以BSD-like 许可证的形式发布，作为一款轻量级 Web/反向代理 服务器以及电子邮件（IMAP/POP3）代理服务器，其主要特点是每条连接占有内存少，并发能力强，常用于Web服务器、反向代理、负载均衡以及HTTP缓存等场景。 编译安装(推荐)环境准备gcc 安装 nginx 需要先将官网下载的源码进行编译，编译依赖 gcc 环境，如果没有 gcc 环境，则需要安装： 1yum install gcc-c++ PCRE pcre-devel PCRE(Perl Compatible Regular Expressions) 是一个Perl库，包括 perl 兼容的正则表达式库。nginx 的 http 模块使用 pcre 来解析正则表达式，所以需要在 linux 上安装 pcre 库，pcre-devel 是使用 pcre 开发的一个二次开发库，nginx也需要此库。 1yum install -y pcre pcre-devel zlib zlib 库提供了很多种压缩和解压缩的方式， nginx 使用 zlib 对 http 包的内容进行 gzip ，所以需要在 CentOS上安装 zlib 库。 1yum install -y zlib zlib-devel OpenSSL OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。nginx 不仅支持 http 协议，还支持 https（即在ssl协议上传输http），所以需要在 CentOS上 安装 OpenSSL 库。 1yum install -y openssl openssl-devel 安装环境综合命令 1yum -y install gcc gcc-c++ autoconf automake zlib zlib-devel openssl openssl-devel pcre-devel Nginx下载及安装 官方下载地址 命令行下载 1wget -c https://nginx.org/download/nginx-1.14.1.tar.gz 成功结果如下 1234567891011[sange@centos-7 java]$ wget -c https://nginx.org/download/nginx-1.14.1.tar.gz--2019-04-15 22:58:27-- https://nginx.org/download/nginx-1.14.1.tar.gzResolving nginx.org (nginx.org)... 95.211.80.227, 62.210.92.35, 2001:1af8:4060:a004:21::e3Connecting to nginx.org (nginx.org)|95.211.80.227|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 1014040 (990K) [application/octet-stream]Saving to: ‘nginx-1.14.1.tar.gz’100%[======================================&gt;] 1,014,040 210KB/s in 4.7s 2019-04-15 22:58:33 (210 KB/s) - ‘nginx-1.14.1.tar.gz’ saved [1014040/1014040] 解压1tar -zxvf nginx-1.14.1.tar.gz 目录1234567891011drwxr-xr-x. 6 sange sange 4096 Apr 15 23:16 auto # -rw-r--r--. 1 sange sange 287441 Nov 6 21:52 CHANGES-rw-r--r--. 1 sange sange 438114 Nov 6 21:52 CHANGES.rudrwxr-xr-x. 2 sange sange 168 Apr 15 23:16 conf-rwxr-xr-x. 1 sange sange 2502 Nov 6 21:52 configuredrwxr-xr-x. 4 sange sange 72 Apr 15 23:16 contribdrwxr-xr-x. 2 sange sange 40 Apr 15 23:16 html-rw-r--r--. 1 sange sange 1397 Nov 6 21:52 LICENSEdrwxr-xr-x. 2 sange sange 21 Apr 15 23:16 man-rw-r--r--. 1 sange sange 49 Nov 6 21:52 READMEdrwxr-xr-x. 9 sange sange 91 Apr 15 23:16 src 配置使用默认配置即可，也可自定义配置 使用默认配置 12# 安装完成后nginx.conf等相关文件及目录即在 /usr/local/nginx 目录下[sange@centos-7 nginx-1.14.1]$ ./configure --prefix=/usr/local/nginx 自定义配置（不推荐） 12345678910111213./configure # 以下为’./configure‘ 命令的参数，’=‘后为各项参数的默认值--prefix=/usr/local/nginx # Nginx安装路径。--conf-path=/usr/local/nginx/conf/nginx.conf # 在没有给定-c选项下默认的nginx.conf的路径--sbin-path=/usr/local/nginx/sbin # Nginx可执行文件安装路径。--pid-path=/usr/local/nginx/conf/nginx.pid # 在nginx.conf中没有指定pid指令的情况下，默认的nginx.pid的路径--lock-path=/var/lock/nginx.lock # nginx.lock文件的路径--error-log-path=/var/log/nginx/error.log # 在nginx.conf中没有指定error_log指令的情况下，默认的错误日志的路径--http-log-path=/var/log/nginx/access.log # 在nginx.conf中没有指定access_log指令的情况下，默认的访问日志的路径# 其他参数含义，一般默认即可--with-* # 表明启用某些功能模块--without-* # 表明禁用某些功能模块 编译及安装1[sange@centos-7 nginx-1.14.1]$ sudo make &amp; make install 操作命令1234567891011[sange@centos-7 nginx-1.14.1]$ whereis nginx # 查找安装目录nginx: /usr/local/nginx# 进入安装目录下的二进制执行文件目录进行相关操作[sange@centos-7 nginx-1.14.1]$ cd /usr/local/nginx/sbin/ # 以下为nginx操作命令./nginx # 启动 nginx./nginx -s stop # 此方式相当于先查出nginx进程id再使用kill命令强制杀掉进程./nginx -s quit # 此方式停止步骤是待nginx进程处理任务完毕进行停止./nginx -s reload # 当修改 nginx.conf 后重新加载配置文件令其生效 开机自启动即在rc.local增加启动代码就可以了。 1vi /etc/rc.local 增加一行 /usr/local/nginx/sbin/nginx，具体如下： 1234567891011121314#!/bin/bash# THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES## It is highly advisable to create own systemd services or udev rules# to run scripts during boot instead of using this file.## In contrast to previous versions due to parallel execution during boot# this script will NOT be run after all other services.## Please note that you must run 'chmod +x /etc/rc.d/rc.local' to ensure# that this script will be executed during boot.touch /var/lock/subsys/local/usr/local/nginx/sbin/nginx # 增加的一行 设置rc.local非root用户执行权限： 1chmod 755 rc.local YUM安装在CentOS下，yum源不提供nginx的安装，可以通过切换yum源的方法获取安装yum源，下例为官网的yum源。 1sudo rpm -ivh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm 安装命令 1yum install -y nginx 通过whereis nginx查看nginx默认安装路径 12345/etc/nginx/ # Nginx默认配置路径，nginx.conf在此/var/run/nginx.pid # PID目录/var/log/nginx/error.log # 错误日志/var/log/nginx/access.log # 访问日志/usr/share/nginx/html # 默认站点目录 测试命令 1234nginx -t # 测试成功结果nginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful 开机自启动 1sudo systemctl enable nginx 操作命令 123sudo systemctl start nginx # 启动服务sudo systemctl restart nginx # 停止服务sudo systemctl reload nginx # 重新加载配置 yum卸载nginx命令 1yum remove -y nginx 防火墙问题 因CentOS 7 防火墙未开放80端口导致本机不能成功访问虚拟机问题 CentOS 7 防火墙相关命令查看已开放端口 1sudo firewall-cmd --list-ports 开放80端口 1234567# ContOS 7 防火墙命令改为 `firewall`, 而7以下的防火墙命令为 `iptables`(且具体命令也不同)sudo firewall-cmd --zone=public --add-port=80/tcp --permanent# 其他指令含义：–zone #作用域–add-port=80/tcp #添加端口，格式为：端口/通讯协议–permanent #永久生效，没有此参数重启后失效 设置完成之后需重启防火墙 123sudo firewall-cmd --reload #重启firewallsudo systemctl stop firewalld.service #停止firewallsudo systemctl disable firewalld.service #禁止firewall开机启动 CentOS 7以下防火墙相关命令开放80端口 1sudo /sbin/iptables -I INPUT -p tcp --dport 80 -j ACCEPT 保存 1sudo /etc/rc.d/init.d/iptables save 查看开放的端口 1sudo /etc/init.d/iptables status 开启与关闭防火墙 1234567# 永久性生效，重启后不会复原sudo chkconfig iptables on # 开启sudo chkconfig iptables off # 关闭# 即时生效，重启后复原sudo service iptables start # 开启sudo service iptables stop # 关闭 参考文章 mafly Deep_Deep_Learning 金武飞扬 Guoye","categories":[{"name":"中间件","slug":"中间件","permalink":"https://sangedon.cn/categories/中间件/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://sangedon.cn/tags/服务器/"},{"name":"学习笔记","slug":"学习笔记","permalink":"https://sangedon.cn/tags/学习笔记/"}]},{"title":"博文列表","slug":"收藏列表","date":"2019-06-13T08:25:18.000Z","updated":"2020-10-10T04:25:51.020Z","comments":true,"path":"paper/收藏列表/","link":"","permalink":"https://sangedon.cn/paper/收藏列表/","excerpt":"","text":"MySQL/InnoDB中，乐观锁、悲观锁、共享锁、排它锁、行锁、表锁、死锁概念的理解 详细深入分析Java ClassLoader 工作机制 Java内存模型 MySQL优化面试","categories":[{"name":"收藏","slug":"收藏","permalink":"https://sangedon.cn/categories/收藏/"}],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://sangedon.cn/tags/学习笔记/"}]},{"title":"2019学习生活规划","slug":"2019学习生活规划","date":"2019-05-25T13:03:22.000Z","updated":"2020-09-23T05:14:55.464Z","comments":true,"path":"paper/2019学习生活规划/","link":"","permalink":"https://sangedon.cn/paper/2019学习生活规划/","excerpt":"知之真切笃实处，即是行；行之明觉精察处，即是知，知行工夫本不可离。 — 知行录","text":"知之真切笃实处，即是行；行之明觉精察处，即是知，知行工夫本不可离。 — 知行录 读书计划⭐️ 骗钱的 ⭐️⭐️ 内容一般，表达一般 ⭐️⭐️⭐️ 内容尚可，表达一般 一次就够 ⭐️⭐️⭐️⭐️内容丰富，表达较好 ⭐️⭐️⭐️⭐️⭐️ 内容经典，表达较好 值得再看 HeadFirst 设计模式 ⭐️⭐️⭐️⭐️ 3.12 Java 开发手册 ⭐️⭐️⭐️ 2.26 码处高效 ⭐️⭐️⭐️ 3.2 鸟哥的Linux私房菜 ⭐️⭐️⭐️ 前七章：3.19 SQL必知必会 ⭐️⭐️⭐️ 3.5 高性能MySQL ⭐️⭐️⭐️⭐️ 前六章：3.26 剑指Offer ⭐️⭐️⭐️ 5.11 Thinking In Java ⭐️⭐️⭐️⭐️ 程序源代码面试指南 ⭐️⭐️⭐️⭐️ 7.29 数据结构与算法分析 ⭐️⭐️⭐️ 2.18 深入理解JVM ⭐️⭐️⭐️⭐️⭐️ 5.7 Java并发编程之美 ⭐️⭐️⭐️⭐️ 7.07 Java并发编程的艺术 ⭐️⭐️ 6.25 JavaScript高级程序设计 ⭐️⭐️⭐️⭐️ 5.17 深入分析 Java Web 技术内幕 ⭐️⭐️ 7.12 大型网站技术架构—核心原理与案例分析 ⭐️⭐️⭐️⭐️ 7.03 网络是怎样跑起来的 ⭐️⭐️⭐️⭐️ 7.17 大话设计模式 ⭐️⭐️⭐️⭐️ 7.23 spring 揭秘 ⭐️⭐️⭐️⭐️ 前8章 7.26 Python 3 网络爬虫开发实战 ⭐️⭐️⭐️ 前6章 7.19 程序是怎样跑起来的 Redis开发与运维 Redis设计与实现 netty实战 Linux命令行与shell脚本编程大全 知行录 技术学习 深入学习理解Java基础知识，如动态代理，注解，反射等，提高面向对象编程的认识 理解Spring基本原理，MVC 框架以及Mybatis的基本实现思路 学习SpringBoot，了解其无配置的原理，理解 restful 风格编程 深入学习MySQL 学习 Redis 学习NIO以及netty框架 学习Nginx 学习Docker 学习 dubbo，了解RPC框架 了解服务器，如Tomcat，Jetty 了解Spring Cloud及分布式架构基础知识 继续学习Python 习惯培养 每周六爬山 早睡 控制饮食口味，少辣","categories":[{"name":"随笔","slug":"随笔","permalink":"https://sangedon.cn/categories/随笔/"}],"tags":[{"name":"规划","slug":"规划","permalink":"https://sangedon.cn/tags/规划/"}]},{"title":"分布式锁的概念及实现","slug":"分布式锁的概念及实现","date":"2019-05-20T08:45:09.000Z","updated":"2020-10-21T14:16:25.408Z","comments":true,"path":"paper/分布式锁的概念及实现/","link":"","permalink":"https://sangedon.cn/paper/分布式锁的概念及实现/","excerpt":"","text":"对于运行在同一个JVM中的单进程程序而言，要实现线程同步操作可使用语言和类库提供的锁，而对于如今分布在不同服务器上运行的程序而言，要实现线程同步操作，语言和类库提供的锁已不能满足需求，因此，对于此类场景，则可使用分布式锁。分布式锁的实现有多种形式，常见的主要有三种实现方式，如：基于数据库乐观锁；基于 redis 的 set 操作；基于 zookeeper 临时有序节点的特性 基于数据库实现基于数据库表 基于数据库的实现方式的核心思想是：在数据库中创建一个表，表中包含方法名（资源）等字段，并在方法名字段上创建唯一索引，想要执行某个方法，就使用这个方法名向表中插入数据，成功插入则获取锁，执行完成后删除对应的行数据释放锁。 创建被锁定方法或资源表 1234567CREATE TABLE `methodLock` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键', `method_name` varchar(64) NOT NULL DEFAULT '' COMMENT '锁定的方法名', `desc` varchar(1024) NOT NULL DEFAULT '备注信息', `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '保存数据时间，自动生成', PRIMARY KEY (`id`), UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='锁定中的方法'; 获取锁，锁定资源(方法或资源) 1insert into methodLock(method_name,desc) values (‘method_name’,‘desc’) 当要获取资源或执行某个方法时，向表中插入该方法记录，由于方法名为唯一索引，所以插入成功则表明已成功获取锁，否则失败 释放锁 1delete from methodLock where method_name ='method_name' 当方法执行完毕时，删除插入的记录即可释放锁，其他进程中的线程即可通过插入记录获取锁 基于数据库排他锁 除了可以通过增删操作数据表中的记录以外，其实还可以借助数据中自带的锁来实现分布式锁。我们还用刚刚创建的那张数据库表，通过数据库的排他锁来实现分布式锁。主要 基于MySql的InnoDB引擎，当进行for update操作时，数据库会在查询过程中为当前查询添加排它锁 获取锁(加锁) 123456789101112131415public boolean lock()&#123; connection.setAutoCommit(false) while(true)&#123; try&#123; // 在查询语句后面增加`for update`，数据库会在查询过程中给数据库表增加排他锁 result = select * from methodLock where method_name=xxx for update; if(result==null)&#123; return true; &#125; &#125;catch(Exception e)&#123; &#125; sleep(1000); &#125; return false;&#125; 需要注意的是：InnoDB引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。如果我们需要使用行级锁，就要为method_name添加索引，并且一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。 我们可以认为获得排它锁的线程即获得了分布式锁，当获取到锁之后，就可以执行方法的业务逻辑，执行完方法之后，再通过提交事物方法解锁： 释放锁 123public void unlock()&#123; connection.commit();&#125; 这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。 for update语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。 使用排它锁的方式，服务宕机之后数据库会自己把锁释放掉。 存在的问题 无法直接解决数据库单点和可重入问题。 我们知道，Mysql执行查询语句之前会进行查询优化，因此，尽管我们对method_name使用了唯一索引，且使用for update来显示使用行级锁，但是查询时是否使用索引具体还要根据Mysql根据内部优化策略判断，如果数据量较小的时候，Mysql可能会认为全表扫描效率更高，则不会使用索引而导致InnoDB使用表锁，此时将导致需要获取其他锁的线程阻塞 如果某个事物长时间占用排它锁，导致长时间占用数据库连接，若类似的耗时连接较多，则数据库连接池将支持不住 可优化 因为是基于数据库实现的，数据库的可用性和性能将直接影响分布式锁的可用性及性能，所以，数据库需要双机部署、数据同步、主从切换； 不具备可重入的特性，因为同一个线程在释放锁之前，行数据一直存在，无法再次成功插入数据，所以，需要在表中新增一列，用于记录当前获取到锁的机器和线程信息，在再次获取锁的时候，先查询表中机器和线程信息是否和当前机器和线程相同，若相同则直接获取锁； 没有锁失效机制，因为有可能出现成功插入数据后，服务器宕机了，对应的数据没有被删除，当服务恢复后一直获取不到锁，所以，需要在表中新增一列，用于记录失效时间，并且需要有定时任务清除这些失效的数据； 不具备阻塞锁特性，获取不到锁直接返回失败，所以需要优化获取逻辑，循环多次去获取。 在实施的过程中会遇到各种不同的问题，为了解决这些问题，实现方式将会越来越复杂；依赖数据库需要一定的资源开销，性能问题需要考虑。 小结 基于数据库实现的两种方式都是依赖数据库的一张表，一种是通过表中的记录是否存在判断是否持有分布式锁，另一种是通过数据库的排他锁来实现分布式锁。 优点 直接借助数据库，容易理解。 缺点 有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。 操作数据库需要一定的开销，性能问题需要考虑。 使用数据库的行级锁并不一定靠谱，尤其是当我们的锁表并不大的时候。 基于Redis实现 利用Redis的set命令。此命令是原子性操作，只有在key不存在的情况下，才能成功。 加锁 最简单的方法是使用set命令。例如想要给一种商品的秒杀活动加锁，key 为 “lock_sale_商品ID” ，value 假设为 11，若 ret 为 1，则表示加锁成功，为 0 则表示已存在 key，加锁失败 12// 加锁伪代码int ret = set（key，1）; 解锁 当获取锁的线程执行完毕，需要释放锁，通过 del操作删除记录，当所释放之后，其他线程即可通过 set操作获取锁 12// 释放锁伪代码del(key) 锁超时 当某个获取所得线程在释放锁之前挂掉，该锁将会长期被占用导致共享资源无法为其他线程提供服务，因此需要为锁添加超时时间，以保证在锁在超时占用时也能被正常释放，Redis 2.6.12 之前 set 操作无法设置超时时间，因此 加锁和设置超时时间的操作为非原子性操作，这会导致在极端情况下，某线程获取锁之后，设置超时时间之前挂掉的话，将无法释放锁。好在后面的版本中 set 操作可设置超时时间 1234567891011// 加锁，设置超时时间 30sint ret = set（key，1，30，NX）// 全过程伪代码如下if（setnx（key，1， 30， NX） == 1）&#123; try &#123; do something ...... &#125; finally &#123; del（key） &#125;&#125; 以上代码还有一个问题，即若线程A超时时长内方法未执行完毕，其他线程（线程B）在此期间也获取到了锁，则A执行完毕后删除锁，而此时的锁为B的锁，为避免这种情况，在删除锁之前需要判断是否是自己添加的锁，则value可设置为当前线程ID 123456789// 伪代码如下// 加锁String threadId = Thread.currentThread().getId()set（key，threadId ，30，NX）// 解锁if（threadId .equals(redisClient.get(key))）&#123; del(key)&#125; 解锁操作中判断操作和解锁操作为非原子性操作，此时可通过lua代码来实现这一段代码 123String luaScript = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\";redisClient.eval(luaScript , Collections.singletonList(key), Collections.singletonList(threadId)); 此时已经解决了大部分问题，但是多个线程同步操作共享资源时，由于过期时间到达而方法未执行完毕，其他线程还是可以获取同步锁，可通过在获取同步锁的同时开启一个守护线程，例如 过期时间30s 则在29s时，将超时时间延长 一定的时间已达到续航的目的，但是需要注意的是，在方法执行完毕时，一定要手动关闭守护线程 小结 使用缓存来代替数据库来实现分布式锁，可以提供更好的性能，同时，很多缓存服务都是集群部署的，可以避免单点问题。并且很多缓存服务都提供了可以用来实现分布式锁的方法，比如redis的setnx方法等。并且，这些缓存服务也都提供了对数据的过期自动删除的支持，可以直接设置超时时间来控制锁的释放。 优点 性能好，实现起来较为方便。 缺点 通过超时时间来控制锁的失效时间并不是十分的靠谱。 基于zookeeper实现 每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个临时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个临时节点删除即可。 Zookeeper的数据结构就像一棵树，由节点（Znode）组成，节点分为四类，利用Zookeeper实现分布式锁主要使用其临时顺序节点的特性完成，节点分类及特性如下： 持久节点 默认的节点类型。创建节点的客户端与zookeeper断开连接后，该节点依旧存在 。 持久顺序节点 所谓顺序节点，就是在创建节点时，Zookeeper根据创建的时间顺序给该节点名称进行编号。 临时节点 和持久节点相反，当创建节点的客户端与zookeeper断开连接后，临时节点会被删除 临时顺序节点 临时顺序节点结合和临时节点和顺序节点的特点：在创建节点时，Zookeeper根据创建的时间顺序给该节点名称进行编号；当创建节点的客户端与zookeeper断开连接后，临时节点会被删除。 实现步骤 获取锁 在Zookeeper当中创建一个持久节点ParentLock。当第一个客户端想要获得锁时，需要在ParentLock这个节点下面创建一个临时顺序节点 Lock1。 Client1查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock1是不是顺序最靠前的一个。如果是第一个节点，则成功获得锁。 如果再有一个客户端 Client2 前来获取锁，则在ParentLock下载再创建一个临时顺序节点Lock2。 Client2查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock2是不是顺序最靠前的一个，结果发现节点Lock2并不是最小的。 Client2向排序仅比它靠前的节点Lock1注册Watcher，用于监听Lock1节点是否存在。这意味着Client2抢锁失败，进入了等待状态。 如果又有一个客户端Client3前来获取锁，则在ParentLock下载再创建一个临时顺序节点Lock3。 Client3查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock3是不是顺序最靠前的一个，结果同样发现节点Lock3并不是最小的。于是，Client3向排序仅比它靠前的节点Lock2注册Watcher，用于监听Lock2节点是否存在。这意味着Client3同样抢锁失败，进入了等待状态。 这样一来，Client1得到了锁，Client2监听了Lock1，Client3监听了Lock2。这恰恰形成了一个等待队列，很像是Java当中ReentrantLock所依赖的AQS（AbstractQueuedSynchronizer）。 释放锁 释放锁分为两种情况： 任务完成，客户端显示释放 当任务完成时，Client1会显示调用删除节点Lock1的指令。 任务执行过程中，客户端崩溃 获得锁的Client1在任务执行过程中，如果程序崩溃，则会断开与Zookeeper服务端的链接。根据临时节点的特性，相关联的节点Lock1会随之自动删除。 由于Client2一直监听着Lock1的存在状态，当Lock1节点被删除，Client2会立刻收到通知。这时候Client2会再次查询ParentLock下面的所有节点，确认自己创建的节点Lock2是不是目前最小的节点。如果是最小，则Client2顺理成章获得了锁。 同理，如果Client2也因为任务完成或者节点崩溃而删除了节点Lock2，那么Client3就会接到通知。最终，Client3成功得到了锁。 Zookeeper可解决问题 使用Zookeeper可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在ZK中创建一个临时节点，一旦客户端获取到锁之后突然挂掉（Session连接断开），那么这个临时节点就会自动删除掉。其他客户端就可以再次获得锁。 使用Zookeeper可以实现阻塞的锁，客户端可以通过在ZK中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。 使用Zookeeper也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。 使用Zookeeper可以有效的解决单点问题，ZK是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。 使用Zookeeper存在的问题使用ZK实现的分布式锁好像完全符合了本文开头我们对一个分布式锁的所有期望。但是，其实并不是，Zookeeper实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同步到所有的Follower机器上。 其实，使用Zookeeper也有可能带来并发问题，只是并不常见而已。考虑这样的情况，由于网络抖动，客户端可ZK集群的session连接断了，那么zk以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。就可能产生并发问题。这个问题不常见是因为zk有重试机制，一旦zk集群检测不到客户端的心跳，就会重试，Curator客户端支持多种重试策略。多次重试之后还不行的话才会删除临时节点。（所以，选择一个合适的重试策略也比较重要，要在锁的粒度和并发之间找一个平衡。） 小结 优点 有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题。实现起来较为简单。 缺点 性能上不如使用缓存实现分布式锁。 需要对ZK的原理有所了解。 总结上面三种方式，均无法在复杂性、可靠性、性能等方面无法同时满足，所以，我们需要根据不同的应用场景选择适合的实现方式。 数据库实现容易理解，且易于实现，但是性能和可靠性方面较差 Zookeeper实现方式最难理解和实现，但是可靠性好 Redis实现方式性能较好，可靠性稍差与zookeeper 参考文章程序员小灰 Java后端技术","categories":[{"name":"Java","slug":"Java","permalink":"https://sangedon.cn/categories/Java/"}],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://sangedon.cn/tags/学习笔记/"},{"name":"分布式","slug":"分布式","permalink":"https://sangedon.cn/tags/分布式/"}]},{"title":"滑动窗口问题","slug":"滑动窗口问题","date":"2019-05-20T07:16:23.000Z","updated":"2020-09-23T05:14:55.473Z","comments":true,"path":"paper/滑动窗口问题/","link":"","permalink":"https://sangedon.cn/paper/滑动窗口问题/","excerpt":"","text":"滑动窗口是数组/字符串问题中常用的抽象概念。 窗口通常是在数组/字符串中由开始和结束索引定义的一系列元素的集合，即 [i, j)（左闭，右开）。而滑动窗口是可以将两个边界向某一方向“滑动”的窗口。例如，我们将 [i, j) 向右滑动 1 个元素，则它将变为 [i+1, j+1)（左闭，右开）。 问题：给定一个字符串，请你找出其中不含有重复字符的 最长子串 的长度。 暴力法 比较暴力的方法，嵌套两次循环，时间复杂度为O(n^2)，具体思路为：使用一个双端队列，保存遍历到当前字符时不重复的字符串，下一个字符如果存在于队列中，则遍历到下一个字符时的子串长度为两个重复字符之间的距离，否则为上一个不重复子串长度加1 本方法适用于记录每一个不重复子串的求解，不适用于仅需要最长子串长度的求解 123456789101112131415161718192021222324252627282930313233343536373839public int lengthOfLongestSubstring(String s) &#123; if (s == null || s.length() == 0)&#123; return 0; &#125; LinkedList&lt;Character&gt; queue = new LinkedList&lt;&gt;(); queue.offer(s.charAt(0)); int index = 1; int max = 1; while (index &lt; s.length())&#123; char temp = s.charAt(index); int s1 = isInQueue(queue, temp); if (s1 &gt;= max)&#123; max = s1; &#125; index ++; &#125; return max; &#125; // 返回队列中与目标字符相同字符的距离，即遍历到当前字符时最长不重复长度 private int isInQueue(LinkedList&lt;Character&gt; queue, char c)&#123; LinkedList&lt;Character&gt; queueT = new LinkedList&lt;&gt;(); int flag = 0; while (!queue.isEmpty())&#123; if (queue.peekLast()!=c)&#123; queueT.offer(queue.pollLast()); flag ++; &#125; else&#123; while(!queue.isEmpty())&#123; queue.poll(); &#125; &#125; &#125; while (!queueT.isEmpty())&#123; queue.offer(queueT.pollLast()); &#125; queue.offer(c); return flag + 1;&#125; 使用hash表记录不重复子串的字符，可分别使用Set和Map or char[256]字符数组 使用Set， 时间复杂度为O(2n) —&gt; O(n)，通过使用 hash表作为滑动窗口，检查当前字符是否在不重复子串中仅需O(1)的时间，当前使用 HashSet 将字符存储在当前窗口[i, j)）中。 然后向右侧滑动索引 j，如果它不在 HashSet 中，我们会继续滑动j。直到s[j]已经存在于 HashSet 中。此时，找到的没有重复字符的最长子字符串将会以索引 i开头。当对所有的 i 这样做，就可以得到答案。 12345678910111213141516public int lengthOfLongestSubstring(String s) &#123; if (s == null || s.length() == 0)&#123; return 0; &#125; Set&lt;Character&gt; set = new HashSet&lt;&gt;(); int i = 0, j = 0, max = 0; while(i &lt;= j &amp;&amp; j &lt; s.length())&#123; if (!set.contains(s.charAt(j)))&#123; set.add(s.charAt(j++)); max = Math.max(max, j - i); &#125; else &#123; set.remove(s.charAt(i ++)); &#125; &#125; return max;&#125; 使用HashMap，时间复杂度为O(n)定义字符到索引的映射，而不是使用集合来判断一个字符是否存在。 当找到重复的字符时，可以立即跳过该窗口，也就是说，如果 s[j]在 [i, j)有与j&#39;的字符，我们不需要逐渐增加i以直接跳过[i，j&#39;]，并将j&#39; + 1。 123456789101112public int lengthOfLongestSubstring(String s) &#123; int n = s.length(), ans = 0; Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); for (int j = 0, i = 0; j &lt; n; j++) &#123; if (map.containsKey(s.charAt(j))) &#123; i = Math.max(map.get(s.charAt(j)), i); &#125; ans = Math.max(ans, j - i + 1); map.put(s.charAt(j), j + 1); &#125; return ans;&#125; 使用char数组代替HashMap，时间复杂度为O(n)，将会节省一定的空间，具体思路同HashMap 12345678910public int lengthOfLongestSubstring(String s) &#123; int n = s.length(), ans = 0; int[] index = new int[128]; for (int j = 0, i = 0; j &lt; n; j++) &#123; i = Math.max(index[s.charAt(j)], i); ans = Math.max(ans, j - i + 1); index[s.charAt(j)] = j + 1; &#125; return ans;&#125; 问题：有一个整形数组arr和一个大小为k的窗口从数组最左边滑动到最右边，窗口每次滑动一个位置，返回每个窗口内的最大值组成的数组 总结","categories":[{"name":"算法","slug":"算法","permalink":"https://sangedon.cn/categories/算法/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://sangedon.cn/tags/LeetCode/"}]}]}