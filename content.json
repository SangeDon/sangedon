{"meta":{"title":"Sange","subtitle":null,"description":null,"author":"董先生","url":"http://sangedon.cn","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2019-05-17T08:23:43.000Z","updated":"2019-05-17T06:45:01.000Z","comments":false,"path":"/404.html","permalink":"http://sangedon.cn//404.html","excerpt":"","text":""},{"title":"关于","date":"2019-05-16T08:32:24.000Z","updated":"2019-05-21T12:12:27.000Z","comments":true,"path":"about/index.html","permalink":"http://sangedon.cn/about/index.html","excerpt":"","text":"Email: sangedong@outlook.comWechat: ssangedon"},{"title":"archives","date":"2019-05-16T08:30:04.000Z","updated":"2019-05-16T08:30:04.000Z","comments":true,"path":"archives/index.html","permalink":"http://sangedon.cn/archives/index.html","excerpt":"","text":""},{"title":"书单","date":"2019-05-17T08:23:17.000Z","updated":"2019-05-17T06:45:01.000Z","comments":false,"path":"books/index.html","permalink":"http://sangedon.cn/books/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2019-05-17T08:25:40.000Z","updated":"2019-05-17T08:25:40.000Z","comments":true,"path":"repository/index.html","permalink":"http://sangedon.cn/repository/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2019-05-17T08:23:11.000Z","updated":"2019-05-17T06:45:01.000Z","comments":true,"path":"links/index.html","permalink":"http://sangedon.cn/links/index.html","excerpt":"","text":""},{"title":"留言本","date":"2019-05-16T08:32:41.000Z","updated":"2019-05-21T12:08:36.000Z","comments":true,"path":"guestbook/index.html","permalink":"http://sangedon.cn/guestbook/index.html","excerpt":"","text":""},{"title":"schedule","date":"2019-05-16T08:30:28.000Z","updated":"2019-05-16T08:30:28.000Z","comments":true,"path":"schedule/index.html","permalink":"http://sangedon.cn/schedule/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-05-16T08:28:32.000Z","updated":"2019-05-17T08:45:55.000Z","comments":true,"path":"tags/index.html","permalink":"http://sangedon.cn/tags/index.html","excerpt":"","text":""},{"title":"历史","date":"2019-05-21T12:10:48.000Z","updated":"2019-05-21T12:10:48.000Z","comments":true,"path":"history/index.html","permalink":"http://sangedon.cn/history/index.html","excerpt":"","text":""},{"title":"分类","date":"2019-05-16T08:32:41.000Z","updated":"2019-05-17T08:47:52.000Z","comments":true,"path":"categories/index.html","permalink":"http://sangedon.cn/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Mysql索引","slug":"Mysql索引","date":"2019-05-21T12:32:24.000Z","updated":"2019-05-21T13:57:48.000Z","comments":true,"path":"2019/05/21/Mysql索引/","link":"","permalink":"http://sangedon.cn/2019/05/21/Mysql索引/","excerpt":"","text":"简介索引是存储引擎中用于快速找到记录的一种数据结构，因此索引优化是对于查询性能优化最有效的手段，尤其是当表中数据越来越大时。然而，不恰当的索引在数据量逐渐增大的情况下会导致性能的急剧下降，而历史经验告诉我们，最优的索引有时比一个好的索引性能要好两个数量级，因此，创建一个真正的最优索引对于提升查询性能非常有利。 小实例 如果在user表的user_id字段上创建了索引，Mysql如何执行下面这条语句？ 1select username from user where user_id = 10; 就像我们查字典一样，Mysql首先在索引中查找值为10的索引，然后根据索引找到user_id为10的所有行并返回 索引的类型索引是在存储引擎层而非服务器层实现的，不同的存储引擎对于索引均有各自的实现，且同一种索引在不同的存储引擎中实现方式也可能不同 B-Tree索引一般我们所谈论的引擎在没有特别指明时多为B-Tree索引 Hash索引基于哈希表实现，只有精确匹配的查询才有效，对于每行数据，存储引擎都会对所有的索引列计算一个哈希码，不同的键值计算的哈希码不一致，而哈希索引将所有的哈希码存储在索引中，同时保存指向每行记录的指针。 如果多行的索引列计算的哈希值相同，索引会以链表的方式存放多个记录的指针到同一个哈希码条目中 查询过程 1select * from user where username = 'sange'; 如以上查询语句，若使用的是哈希索引，且索引列为username，则Mysql先根据where子句中的username的值计算哈希值，如 hash(‘sange’’) = 8080，Mysql在索引中查询值为8080的索引，则可以查到到指向username为sange的行，最后比较第三行的值是否和要查找的值相同 特点 只包含哈希值和行指针，不存储字段值，因此不能避免读取行。由于访问内存中的行速度非常快，因此，多数情况下对于性能影响并不明显 哈希索引数据并非按照顺序存储，因此无法用于排序 由于是以所有的索引列的值来计算哈希值，因此也不支持部分索引匹配查找；如索引列为A，B，查询时只有索引列A | B，此时无法使用索引","categories":[{"name":"数据库","slug":"数据库","permalink":"http://sangedon.cn/categories/数据库/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://sangedon.cn/tags/读书笔记/"},{"name":"高性能Mysql","slug":"高性能Mysql","permalink":"http://sangedon.cn/tags/高性能Mysql/"}]},{"title":"分布式锁的概念及实现","slug":"分布式锁的概念及实现","date":"2019-05-20T08:45:09.000Z","updated":"2019-05-21T13:14:46.000Z","comments":true,"path":"2019/05/20/分布式锁的概念及实现/","link":"","permalink":"http://sangedon.cn/2019/05/20/分布式锁的概念及实现/","excerpt":"","text":"概念 对于运行在同一个JVM中的单进程程序而言，要实现线程同步操作可使用语言和类库提供的锁，而对于如今分布在不同服务器上运行的程序而言，要实现线程同步操作，语言和类库提供的锁已不能满足需求，因此，对于此类场景，则可使用分布式锁。分布式锁的实现有多种形式，常见的主要有三种实现方式，如：基于数据库乐观锁；基于 redis 的 set 操作；基于 zookeeper 临时有序节点的特性 场景基于数据库实现基于数据库表 基于数据库的实现方式的核心思想是：在数据库中创建一个表，表中包含方法名（资源）等字段，并在方法名字段上创建唯一索引，想要执行某个方法，就使用这个方法名向表中插入数据，成功插入则获取锁，执行完成后删除对应的行数据释放锁。 创建被锁定方法或资源表 1234567CREATE TABLE `methodLock` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键', `method_name` varchar(64) NOT NULL DEFAULT '' COMMENT '锁定的方法名', `desc` varchar(1024) NOT NULL DEFAULT '备注信息', `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '保存数据时间，自动生成', PRIMARY KEY (`id`), UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='锁定中的方法'; 获取锁，锁定资源(方法或资源) 1insert into methodLock(method_name,desc) values (‘method_name’,‘desc’) 当要获取资源或执行某个方法时，向表中插入该方法记录，由于方法名为唯一索引，所以插入成功则表明已成功获取锁，否则失败 释放锁 1delete from methodLock where method_name ='method_name' 当方法执行完毕时，删除插入的记录即可释放锁，其他进程中的线程即可通过插入记录获取锁 基于数据库排他锁 除了可以通过增删操作数据表中的记录以外，其实还可以借助数据中自带的锁来实现分布式锁。我们还用刚刚创建的那张数据库表，通过数据库的排他锁来实现分布式锁。主要 基于MySql的InnoDB引擎，当进行for update操作时，数据库会在查询过程中为当前查询添加排它锁 获取锁(加锁) 123456789101112131415public boolean lock()&#123; connection.setAutoCommit(false) while(true)&#123; try&#123; // 在查询语句后面增加`for update`，数据库会在查询过程中给数据库表增加排他锁 result = select * from methodLock where method_name=xxx for update; if(result==null)&#123; return true; &#125; &#125;catch(Exception e)&#123; &#125; sleep(1000); &#125; return false;&#125; 需要注意的是：InnoDB引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。如果我们需要使用行级锁，就要为method_name添加索引，并且一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。 我们可以认为获得排它锁的线程即获得了分布式锁，当获取到锁之后，就可以执行方法的业务逻辑，执行完方法之后，再通过提交事物方法解锁： 释放锁 123public void unlock()&#123; connection.commit();&#125; 这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。 for update语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。 使用排它锁的方式，服务宕机之后数据库会自己把锁释放掉。 存在的问题 无法直接解决数据库单点和可重入问题。 我们知道，Mysql执行查询语句之前会进行查询优化，因此，尽管我们对method_name使用了唯一索引，且使用for update来显示使用行级锁，但是查询时是否使用索引具体还要根据Mysql根据内部优化策略判断，如果数据量较小的时候，Mysql可能会认为全表扫描效率更高，则不会使用索引而导致InnoDB使用表锁，此时将导致需要获取其他锁的线程阻塞 如果某个事物长时间占用排它锁，导致长时间占用数据库连接，若类似的耗时连接较多，则数据库连接池将支持不住 可优化 因为是基于数据库实现的，数据库的可用性和性能将直接影响分布式锁的可用性及性能，所以，数据库需要双机部署、数据同步、主从切换； 不具备可重入的特性，因为同一个线程在释放锁之前，行数据一直存在，无法再次成功插入数据，所以，需要在表中新增一列，用于记录当前获取到锁的机器和线程信息，在再次获取锁的时候，先查询表中机器和线程信息是否和当前机器和线程相同，若相同则直接获取锁； 没有锁失效机制，因为有可能出现成功插入数据后，服务器宕机了，对应的数据没有被删除，当服务恢复后一直获取不到锁，所以，需要在表中新增一列，用于记录失效时间，并且需要有定时任务清除这些失效的数据； 不具备阻塞锁特性，获取不到锁直接返回失败，所以需要优化获取逻辑，循环多次去获取。 在实施的过程中会遇到各种不同的问题，为了解决这些问题，实现方式将会越来越复杂；依赖数据库需要一定的资源开销，性能问题需要考虑。 小结 基于数据库实现的两种方式都是依赖数据库的一张表，一种是通过表中的记录是否存在判断是否持有分布式锁，另一种是通过数据库的排他锁来实现分布式锁。 优点 直接借助数据库，容易理解。 缺点 有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。 操作数据库需要一定的开销，性能问题需要考虑。 使用数据库的行级锁并不一定靠谱，尤其是当我们的锁表并不大的时候。 基于Redis实现 利用Redis的set命令。此命令是原子性操作，只有在key不存在的情况下，才能成功。 加锁 最简单的方法是使用set命令。例如想要给一种商品的秒杀活动加锁，key 为 “lock_sale_商品ID” ，value 假设为 11，若 ret 为 1，则表示加锁成功，为 0 则表示已存在 key，加锁失败 12// 加锁伪代码int ret = set（key，1）; 解锁 当获取锁的线程执行完毕，需要释放锁，通过 del操作删除记录，当所释放之后，其他线程即可通过 set操作获取锁 12// 释放锁伪代码del(key) 锁超时 当某个获取所得线程在释放锁之前挂掉，该锁将会长期被占用导致共享资源无法为其他线程提供服务，因此需要为锁添加超时时间，以保证在锁在超时占用时也能被正常释放，Redis 2.6.12 之前 set 操作无法设置超时时间，因此 加锁和设置超时时间的操作为非原子性操作，这会导致在极端情况下，某线程获取锁之后，设置超时时间之前挂掉的话，将无法释放锁。好在后面的版本中 set 操作可设置超时时间 1234567891011// 加锁，设置超时时间 30sint ret = set（key，1，30，NX）// 全过程伪代码如下if（setnx（key，1， 30， NX） == 1）&#123; try &#123; do something ...... &#125; finally &#123; del（key） &#125;&#125; 以上代码还有一个问题，即若线程A超时时长内方法未执行完毕，其他线程（线程B）在此期间也获取到了锁，则A执行完毕后删除锁，而此时的锁为B的锁，为避免这种情况，在删除锁之前需要判断是否是自己添加的锁，则value可设置为当前线程ID 123456789// 伪代码如下// 加锁String threadId = Thread.currentThread().getId()set（key，threadId ，30，NX）// 解锁if（threadId .equals(redisClient.get(key))）&#123; del(key)&#125; 解锁操作中判断操作和解锁操作为非原子性操作，此时可通过lua代码来实现这一段代码 123String luaScript = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\";redisClient.eval(luaScript , Collections.singletonList(key), Collections.singletonList(threadId)); 此时已经解决了大部分问题，但是多个线程同步操作共享资源时，由于过期时间到达而方法未执行完毕，其他线程还是可以获取同步锁，可通过在获取同步锁的同时开启一个守护线程，例如 过期时间30s 则在29s时，将超时时间延长 一定的时间已达到续航的目的，但是需要注意的是，在方法执行完毕时，一定要手动关闭守护线程 小结 使用缓存来代替数据库来实现分布式锁，可以提供更好的性能，同时，很多缓存服务都是集群部署的，可以避免单点问题。并且很多缓存服务都提供了可以用来实现分布式锁的方法，比如redis的setnx方法等。并且，这些缓存服务也都提供了对数据的过期自动删除的支持，可以直接设置超时时间来控制锁的释放。 优点 性能好，实现起来较为方便。 缺点 通过超时时间来控制锁的失效时间并不是十分的靠谱。 基于zookeeper实现 每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个临时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个临时节点删除即可。 Zookeeper的数据结构就像一棵树，由节点（Znode）组成，节点分为四类，利用Zookeeper实现分布式锁主要使用其临时顺序节点的特性完成，节点分类及特性如下： 持久节点 默认的节点类型。创建节点的客户端与zookeeper断开连接后，该节点依旧存在 。 持久顺序节点 所谓顺序节点，就是在创建节点时，Zookeeper根据创建的时间顺序给该节点名称进行编号。 临时节点 和持久节点相反，当创建节点的客户端与zookeeper断开连接后，临时节点会被删除 临时顺序节点 临时顺序节点结合和临时节点和顺序节点的特点：在创建节点时，Zookeeper根据创建的时间顺序给该节点名称进行编号；当创建节点的客户端与zookeeper断开连接后，临时节点会被删除。 实现步骤 获取锁 在Zookeeper当中创建一个持久节点ParentLock。当第一个客户端想要获得锁时，需要在ParentLock这个节点下面创建一个临时顺序节点 Lock1。 Client1查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock1是不是顺序最靠前的一个。如果是第一个节点，则成功获得锁。 如果再有一个客户端 Client2 前来获取锁，则在ParentLock下载再创建一个临时顺序节点Lock2。 Client2查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock2是不是顺序最靠前的一个，结果发现节点Lock2并不是最小的。 Client2向排序仅比它靠前的节点Lock1注册Watcher，用于监听Lock1节点是否存在。这意味着Client2抢锁失败，进入了等待状态。 如果又有一个客户端Client3前来获取锁，则在ParentLock下载再创建一个临时顺序节点Lock3。 Client3查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock3是不是顺序最靠前的一个，结果同样发现节点Lock3并不是最小的。于是，Client3向排序仅比它靠前的节点Lock2注册Watcher，用于监听Lock2节点是否存在。这意味着Client3同样抢锁失败，进入了等待状态。 这样一来，Client1得到了锁，Client2监听了Lock1，Client3监听了Lock2。这恰恰形成了一个等待队列，很像是Java当中ReentrantLock所依赖的AQS（AbstractQueuedSynchronizer）。 释放锁 释放锁分为两种情况： 任务完成，客户端显示释放 当任务完成时，Client1会显示调用删除节点Lock1的指令。 任务执行过程中，客户端崩溃 获得锁的Client1在任务执行过程中，如果程序崩溃，则会断开与Zookeeper服务端的链接。根据临时节点的特性，相关联的节点Lock1会随之自动删除。 由于Client2一直监听着Lock1的存在状态，当Lock1节点被删除，Client2会立刻收到通知。这时候Client2会再次查询ParentLock下面的所有节点，确认自己创建的节点Lock2是不是目前最小的节点。如果是最小，则Client2顺理成章获得了锁。 同理，如果Client2也因为任务完成或者节点崩溃而删除了节点Lock2，那么Client3就会接到通知。最终，Client3成功得到了锁。 Zookeeper可解决问题 使用Zookeeper可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在ZK中创建一个临时节点，一旦客户端获取到锁之后突然挂掉（Session连接断开），那么这个临时节点就会自动删除掉。其他客户端就可以再次获得锁。 使用Zookeeper可以实现阻塞的锁，客户端可以通过在ZK中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。 使用Zookeeper也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。 使用Zookeeper可以有效的解决单点问题，ZK是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。 使用Zookeeper存在的问题使用ZK实现的分布式锁好像完全符合了本文开头我们对一个分布式锁的所有期望。但是，其实并不是，Zookeeper实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同步到所有的Follower机器上。 其实，使用Zookeeper也有可能带来并发问题，只是并不常见而已。考虑这样的情况，由于网络抖动，客户端可ZK集群的session连接断了，那么zk以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。就可能产生并发问题。这个问题不常见是因为zk有重试机制，一旦zk集群检测不到客户端的心跳，就会重试，Curator客户端支持多种重试策略。多次重试之后还不行的话才会删除临时节点。（所以，选择一个合适的重试策略也比较重要，要在锁的粒度和并发之间找一个平衡。） 小结 优点** 有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题。实现起来较为简单。 缺点 性能上不如使用缓存实现分布式锁。 需要对ZK的原理有所了解。 总结上面三种方式，均无法在复杂性、可靠性、性能等方面无法同时满足，所以，我们需要根据不同的应用场景选择适合的实现方式。 数据库实现容易理解，且易于实现，但是性能和可靠性方面较差 Zookeeper实现方式最难理解和实现，但是可靠性好 Redis实现方式性能较好，可靠性稍差与zookeeper 参考文章程序员小灰 Java后端技术","categories":[{"name":"Java","slug":"Java","permalink":"http://sangedon.cn/categories/Java/"}],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://sangedon.cn/tags/学习笔记/"},{"name":"分布式","slug":"分布式","permalink":"http://sangedon.cn/tags/分布式/"}]},{"title":"滑动窗口问题","slug":"滑动窗口问题","date":"2019-05-20T07:16:23.000Z","updated":"2019-05-21T09:02:34.000Z","comments":true,"path":"2019/05/20/滑动窗口问题/","link":"","permalink":"http://sangedon.cn/2019/05/20/滑动窗口问题/","excerpt":"","text":"简介 滑动窗口是数组/字符串问题中常用的抽象概念。 窗口通常是在数组/字符串中由开始和结束索引定义的一系列元素的集合，即 [i, j)（左闭，右开）。而滑动窗口是可以将两个边界向某一方向“滑动”的窗口。例如，我们将 [i, j) 向右滑动 1 个元素，则它将变为 [i+1, j+1)（左闭，右开）。 问题：给定一个字符串，请你找出其中不含有重复字符的 最长子串 的长度。 暴力法 比较暴力的方法，嵌套两次循环，时间复杂度为O(n^2)，具体思路为：使用一个双端队列，保存遍历到当前字符时不重复的字符串，下一个字符如果存在于队列中，则遍历到下一个字符时的子串长度为两个重复字符之间的距离，否则为上一个不重复子串长度加1 本方法适用于记录每一个不重复子串的求解，不适用于仅需要最长子串长度的求解 123456789101112131415161718192021222324252627282930313233343536373839public int lengthOfLongestSubstring(String s) &#123; if (s == null || s.length() == 0)&#123; return 0; &#125; LinkedList&lt;Character&gt; queue = new LinkedList&lt;&gt;(); queue.offer(s.charAt(0)); int index = 1; int max = 1; while (index &lt; s.length())&#123; char temp = s.charAt(index); int s1 = isInQueue(queue, temp); if (s1 &gt;= max)&#123; max = s1; &#125; index ++; &#125; return max; &#125; // 返回队列中与目标字符相同字符的距离，即遍历到当前字符时最长不重复长度 private int isInQueue(LinkedList&lt;Character&gt; queue, char c)&#123; LinkedList&lt;Character&gt; queueT = new LinkedList&lt;&gt;(); int flag = 0; while (!queue.isEmpty())&#123; if (queue.peekLast()!=c)&#123; queueT.offer(queue.pollLast()); flag ++; &#125; else&#123; while(!queue.isEmpty())&#123; queue.poll(); &#125; &#125; &#125; while (!queueT.isEmpty())&#123; queue.offer(queueT.pollLast()); &#125; queue.offer(c); return flag + 1;&#125; 使用hash表记录不重复子串的字符，可分别使用Set和Map or char[256]字符数组 使用Set， 时间复杂度为O(2n) —&gt; O(n)，通过使用 hash表作为滑动窗口，检查当前字符是否在不重复子串中仅需O(1)的时间，当前使用 HashSet 将字符存储在当前窗口[i, j)）中。 然后向右侧滑动索引 j，如果它不在 HashSet 中，我们会继续滑动j。直到s[j]已经存在于 HashSet 中。此时，找到的没有重复字符的最长子字符串将会以索引 i开头。当对所有的 i 这样做，就可以得到答案。 12345678910111213141516public int lengthOfLongestSubstring(String s) &#123; if (s == null || s.length() == 0)&#123; return 0; &#125; Set&lt;Character&gt; set = new HashSet&lt;&gt;(); int i = 0, j = 0, max = 0; while(i &lt;= j &amp;&amp; j &lt; s.length())&#123; if (!set.contains(s.charAt(j)))&#123; set.add(s.charAt(j++)); max = Math.max(max, j - i); &#125; else &#123; set.remove(s.charAt(i ++)); &#125; &#125; return max;&#125; 使用HashMap，时间复杂度为O(n)定义字符到索引的映射，而不是使用集合来判断一个字符是否存在。 当找到重复的字符时，可以立即跳过该窗口，也就是说，如果 s[j]在 [i, j)有与j&#39;的字符，我们不需要逐渐增加i以直接跳过[i，j&#39;]，并将j&#39; + 1。 123456789101112public int lengthOfLongestSubstring(String s) &#123; int n = s.length(), ans = 0; Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); for (int j = 0, i = 0; j &lt; n; j++) &#123; if (map.containsKey(s.charAt(j))) &#123; i = Math.max(map.get(s.charAt(j)), i); &#125; ans = Math.max(ans, j - i + 1); map.put(s.charAt(j), j + 1); &#125; return ans;&#125; 使用char数组代替HashMap，时间复杂度为O(n)，将会节省一定的空间，具体思路同HashMap 12345678910public int lengthOfLongestSubstring(String s) &#123; int n = s.length(), ans = 0; int[] index = new int[128]; for (int j = 0, i = 0; j &lt; n; j++) &#123; i = Math.max(index[s.charAt(j)], i); ans = Math.max(ans, j - i + 1); index[s.charAt(j)] = j + 1; &#125; return ans;&#125; 总结","categories":[{"name":"算法","slug":"算法","permalink":"http://sangedon.cn/categories/算法/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://sangedon.cn/tags/LeetCode/"}]},{"title":"Guns后台管理框架学习","slug":"Guns后台管理框架学习","date":"2019-05-20T03:06:34.000Z","updated":"2019-05-20T04:46:40.000Z","comments":true,"path":"2019/05/20/Guns后台管理框架学习/","link":"","permalink":"http://sangedon.cn/2019/05/20/Guns后台管理框架学习/","excerpt":"","text":"官方简介 Guns基于SpringBoot 2，致力于做更简洁的后台管理系统。Guns项目代码简洁，注释丰富，上手容易，同时Guns包含许多基础模块(用户管理，角色管理，部门管理，字典管理等10个模块)，可以直接作为一个后台管理系统的脚手架! ## 下载 12# 下载到指定文件夹localhost:IDEA-Workspace sangedon$ git clone https://github.com/stylefeng/Guns.git 部署 通过idea导入，略 启动","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://sangedon.cn/tags/学习笔记/"}]},{"title":"FastDFS在Ubuntu上的安装及使用","slug":"FastDFS在ubuntu上的安装及使用","date":"2019-04-22T02:34:07.000Z","updated":"2019-05-20T00:38:09.000Z","comments":true,"path":"2019/04/22/FastDFS在ubuntu上的安装及使用/","link":"","permalink":"http://sangedon.cn/2019/04/22/FastDFS在ubuntu上的安装及使用/","excerpt":"","text":"安装 libfatscommon 是 fastdfs 常用函数封装的库，需要从github上clone到本地编译安装，如果没有安装git需先安装。 12# 安装 gitapt-get install git 下载安装libfastcommon 1234567891011121314151617# 克隆项目git clone https://github.com/happyfish100/libfastcommon.git# 进入目录cd libfastcommon/# 编译./make.sh# 安装sudo ./make.sh install# 设置环境变量export LD_LIBRARY_PATH=/usr/lib64/# 建立软连接ln -s /usr/lib64/libfastcommon.so /usr/local/lib64/libfastcommon.so 安装FastDFS 12345678# 下载 FastDFSgit clone https://github.com/happyfish100/fastdfs.git# 进入目录cd fastdfs/# 编译安装./make.sh &amp;&amp; ./make.sh install 12345678#暂时直接复制到目标目录，没有其他修改，相关配置可以在跑通后详细阅读和修改cp /usr/local/src/fastdfs/conf/http.conf /etc/fdfs/ #供nginx访问使用cp /usr/local/src/fastdfs/conf/mime.types /etc/fdfs/ #供nginx访问使用#配置文件准备(Notice: 根据本机的角色，按需复制粘贴配置文件!)cp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.confcp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.confcp /etc/fdfs/client.conf.sample /etc/fdfs/client.conf #客户端文件，测试用 获取 fastdfs-nginx-module 此 module 用于避免上传完成后，且 group storage 同步文件完成前，客户端从正在同步的主机处下载文件导致的出错 12345cd /usr/local/srcgit clone https://github.com/happyfish100/fastdfs-nginx-module.git --depth 1cp /usr/local/src/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs 安装Nginx tracker 和 storage 均需要安装 nginx 对于 tracker, nginx 可以均衡负载到不同的 storage 对于 storage, nginx 可以提供反向代理，从而访问数据存储位置的文件 由于需要使用启用非默认 module , 故需要通过源码编译安装，不能使用 yum . 使用源码安装 nginx 的注意事项见《nginx - make install》 123# 安装nginx依赖环境apt-get install libpcre3 libpcre3-devapt-get install zlib1g-dev 将下载好的nginx移动到Ubuntu自定义目录下 1234567891011# 解压nginxtar -xvf nginx-1.14.1.tar.gz# 进入nginx目录cd nginx-1.14.1# 预编译Nginx, 并指定nginx安装目录，增加fastdfs模块./configure --prefix=/usr/local/nginx --add-module=/home/sange/Downloads/fastdfs-nginx-module/src/# 编译安装$ make &amp;&amp; make install 需要配置 nginx, tracker, storage 和 client tracker 和 storage 需要搭配 nginx 使用，故在本教程中， nginx 的配置都是关于 tracker 和 storage 的，与 client 无关。 tracker, storage 和 client 都有自身的配置项，需要单独配置。 12345678910vim /etc/fdfs/tracker.confbase_path=/home/yuqing/FastDFS改为:base_path=/home/dfs#将 tracker 和 storage 的 http.server_port 统一改为80可以正常访问，但是否最优方案，还需要观察http.server_port=8080改为:http.server_port=80","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://sangedon.cn/tags/学习笔记/"}]},{"title":"CentOS 7上Nginx的安装及基本配置","slug":"CentOS 7上nginx安装及相关配置","date":"2019-04-15T13:36:55.000Z","updated":"2019-05-20T00:35:43.000Z","comments":true,"path":"2019/04/15/CentOS 7上nginx安装及相关配置/","link":"","permalink":"http://sangedon.cn/2019/04/15/CentOS 7上nginx安装及相关配置/","excerpt":"","text":"前言Nginx (engine x) 是一个高性能的HTTP和反向代理服务，也是一个IMAP/POP3/SMTP服务。由俄罗斯人伊戈尔·赛索耶夫为Rambler.ru站点用C语言开发的，第一个公开版本0.1.0发布于2004年10月4日，2011年成立同名公司，以提供支持。其源代码以BSD-like 许可证的形式发布，作为一款轻量级 Web/反向代理 服务器以及电子邮件（IMAP/POP3）代理服务器，其主要特点是每条连接占有内存少，并发能力强，常用于Web服务器、反向代理、负载均衡以及HTTP缓存等场景。 编译安装(推荐)环境准备gcc 安装 nginx 需要先将官网下载的源码进行编译，编译依赖 gcc 环境，如果没有 gcc 环境，则需要安装： 1yum install gcc-c++ PCRE pcre-devel PCRE(Perl Compatible Regular Expressions) 是一个Perl库，包括 perl 兼容的正则表达式库。nginx 的 http 模块使用 pcre 来解析正则表达式，所以需要在 linux 上安装 pcre 库，pcre-devel 是使用 pcre 开发的一个二次开发库，nginx也需要此库。 1yum install -y pcre pcre-devel zlib zlib 库提供了很多种压缩和解压缩的方式， nginx 使用 zlib 对 http 包的内容进行 gzip ，所以需要在 CentOS上安装 zlib 库。 1yum install -y zlib zlib-devel OpenSSL OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。nginx 不仅支持 http 协议，还支持 https（即在ssl协议上传输http），所以需要在 CentOS上 安装 OpenSSL 库。 1yum install -y openssl openssl-devel 安装环境综合命令 1yum -y install gcc gcc-c++ autoconf automake zlib zlib-devel openssl openssl-devel pcre-devel Nginx下载及安装 官方下载地址 命令行下载 1wget -c https://nginx.org/download/nginx-1.14.1.tar.gz 成功结果如下 1234567891011[sange@centos-7 java]$ wget -c https://nginx.org/download/nginx-1.14.1.tar.gz--2019-04-15 22:58:27-- https://nginx.org/download/nginx-1.14.1.tar.gzResolving nginx.org (nginx.org)... 95.211.80.227, 62.210.92.35, 2001:1af8:4060:a004:21::e3Connecting to nginx.org (nginx.org)|95.211.80.227|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 1014040 (990K) [application/octet-stream]Saving to: ‘nginx-1.14.1.tar.gz’100%[======================================&gt;] 1,014,040 210KB/s in 4.7s 2019-04-15 22:58:33 (210 KB/s) - ‘nginx-1.14.1.tar.gz’ saved [1014040/1014040] 解压1tar -zxvf nginx-1.14.1.tar.gz 目录1234567891011drwxr-xr-x. 6 sange sange 4096 Apr 15 23:16 auto # -rw-r--r--. 1 sange sange 287441 Nov 6 21:52 CHANGES-rw-r--r--. 1 sange sange 438114 Nov 6 21:52 CHANGES.rudrwxr-xr-x. 2 sange sange 168 Apr 15 23:16 conf-rwxr-xr-x. 1 sange sange 2502 Nov 6 21:52 configuredrwxr-xr-x. 4 sange sange 72 Apr 15 23:16 contribdrwxr-xr-x. 2 sange sange 40 Apr 15 23:16 html-rw-r--r--. 1 sange sange 1397 Nov 6 21:52 LICENSEdrwxr-xr-x. 2 sange sange 21 Apr 15 23:16 man-rw-r--r--. 1 sange sange 49 Nov 6 21:52 READMEdrwxr-xr-x. 9 sange sange 91 Apr 15 23:16 src 配置使用默认配置即可，也可自定义配置 使用默认配置 12# 安装完成后nginx.conf等相关文件及目录即在 /usr/local/nginx 目录下[sange@centos-7 nginx-1.14.1]$ ./configure --prefix=/usr/local/nginx 自定义配置（不推荐） 12345678910111213./configure # 以下为’./configure‘ 命令的参数，’=‘后为各项参数的默认值--prefix=/usr/local/nginx # Nginx安装路径。--conf-path=/usr/local/nginx/conf/nginx.conf # 在没有给定-c选项下默认的nginx.conf的路径--sbin-path=/usr/local/nginx/sbin # Nginx可执行文件安装路径。--pid-path=/usr/local/nginx/conf/nginx.pid # 在nginx.conf中没有指定pid指令的情况下，默认的nginx.pid的路径--lock-path=/var/lock/nginx.lock # nginx.lock文件的路径--error-log-path=/var/log/nginx/error.log # 在nginx.conf中没有指定error_log指令的情况下，默认的错误日志的路径--http-log-path=/var/log/nginx/access.log # 在nginx.conf中没有指定access_log指令的情况下，默认的访问日志的路径# 其他参数含义，一般默认即可--with-* # 表明启用某些功能模块--without-* # 表明禁用某些功能模块 编译及安装1[sange@centos-7 nginx-1.14.1]$ sudo make &amp; make install 操作命令1234567891011[sange@centos-7 nginx-1.14.1]$ whereis nginx # 查找安装目录nginx: /usr/local/nginx# 进入安装目录下的二进制执行文件目录进行相关操作[sange@centos-7 nginx-1.14.1]$ cd /usr/local/nginx/sbin/ # 以下为nginx操作命令./nginx # 启动 nginx./nginx -s stop # 此方式相当于先查出nginx进程id再使用kill命令强制杀掉进程./nginx -s quit # 此方式停止步骤是待nginx进程处理任务完毕进行停止./nginx -s reload # 当修改 nginx.conf 后重新加载配置文件令其生效 开机自启动即在rc.local增加启动代码就可以了。 1vi /etc/rc.local 增加一行 /usr/local/nginx/sbin/nginx，具体如下： 1234567891011121314#!/bin/bash# THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES## It is highly advisable to create own systemd services or udev rules# to run scripts during boot instead of using this file.## In contrast to previous versions due to parallel execution during boot# this script will NOT be run after all other services.## Please note that you must run 'chmod +x /etc/rc.d/rc.local' to ensure# that this script will be executed during boot.touch /var/lock/subsys/local/usr/local/nginx/sbin/nginx # 增加的一行 设置rc.local非root用户执行权限： 1chmod 755 rc.local YUM安装在CentOS下，yum源不提供nginx的安装，可以通过切换yum源的方法获取安装yum源，下例为官网的yum源。 1sudo rpm -ivh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm 安装命令 1yum install -y nginx 通过whereis nginx查看nginx默认安装路径 12345/etc/nginx/ # Nginx默认配置路径，nginx.conf在此/var/run/nginx.pid # PID目录/var/log/nginx/error.log # 错误日志/var/log/nginx/access.log # 访问日志/usr/share/nginx/html # 默认站点目录 测试命令 1234nginx -t # 测试成功结果nginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful 开机自启动 1sudo systemctl enable nginx 操作命令 123sudo systemctl start nginx # 启动服务sudo systemctl restart nginx # 停止服务sudo systemctl reload nginx # 重新加载配置 yum卸载nginx命令 1yum remove -y nginx 防火墙问题 因CentOS 7 防火墙未开放80端口导致本机不能成功访问虚拟机问题 CentOS 7 防火墙相关命令查看已开放端口 1sudo firewall-cmd --list-ports 开放80端口 1234567# ContOS 7 防火墙命令改为 `firewall`, 而7以下的防火墙命令为 `iptables`(且具体命令也不同)sudo firewall-cmd --zone=public --add-port=80/tcp --permanent# 其他指令含义：–zone #作用域–add-port=80/tcp #添加端口，格式为：端口/通讯协议–permanent #永久生效，没有此参数重启后失效 设置完成之后需重启防火墙 123sudo firewall-cmd --reload #重启firewallsudo systemctl stop firewalld.service #停止firewallsudo systemctl disable firewalld.service #禁止firewall开机启动 CentOS 7以下防火墙相关命令开放80端口 1sudo /sbin/iptables -I INPUT -p tcp --dport 80 -j ACCEPT 保存 1sudo /etc/rc.d/init.d/iptables save 查看开放的端口 1sudo /etc/init.d/iptables status 开启与关闭防火墙 1234567# 永久性生效，重启后不会复原sudo chkconfig iptables on # 开启sudo chkconfig iptables off # 关闭# 即时生效，重启后复原sudo service iptables start # 开启sudo service iptables stop # 关闭 参考文章 mafly Deep_Deep_Learning 金武飞扬 Guoye","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://sangedon.cn/tags/学习笔记/"}]}]}